---
title: "LFXC_EEG - behavioral results"
author: "Ivan Grahek"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    theme: default
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## About the code

Experiment: LFXC_EEG 
Code written by: Ivan Grahek (2018-2021)
Description: Code for the analysis of behavioral and EEG data for Experiment 1 of the LFXC_EEG project.  

_This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>._


\newpage

## Importing data
### Behavior
```{r, warning=FALSE, message=FALSE}
# Clear environemnt and import data

# clear the environment
rm(list=ls()) 
#load packages and install them if they're not installed
if (!require("pacman")) install.packages("pacman")
 pacman::p_load(plyr,Rmisc,yarrr,BayesFactor,reshape2,brms, broom, tidyverse, brmstools, BEST, knitr, here, zoo, magrittr, pracma,xtable, Hmisc, ppcor, lme4,MuMIn,MASS, sjPlot, jtools, lmerTest, sjstats,coefplot,R.matlab,RColorBrewer,cowplot,bayesplot,rstan)

#pacman::p_load(tidyverse)
# set seed
set.seed(42) 
# set directory
setwd(here())
# import data
data.raw = read.csv(file = here("Data/Experiment1/Behavior/preprocessed","data104.csv"),header=TRUE,na.strings="NaN")

# take out the participants with low accuracy
# data.raw = subset(data.raw, data.raw$SubID != 1061)
# data.raw = subset(data.raw, data.raw$SubID != 1044)

# take out the participants with 0 correlation between run average and subjective efficacy estimates
# data.raw = subset(data.raw, data.raw$SubID != 1059)
# data.raw = subset(data.raw, data.raw$SubID != 1070)
# data.raw = subset(data.raw, data.raw$SubID != 1043)


# take only odd/even subjects
#data.raw = subset(data.raw, data.raw$SubID %% 2 == 0)

#rename variables and save as factors
data.raw <- data.raw %>% 
     mutate_at(c("Congruency"), funs(recode(., "0" = "Incongruent","1" = "Congruent","2" = "Neutral")))

RewardLag = c("IsRewarded_T1",
                 "IsRewarded_T2",
                 "IsRewarded_T3",
                 "IsRewarded_T4",
                 "IsRewarded_T5",
                 "IsRewarded_T6",
                 "IsRewarded_T7",
                 "IsRewarded_T8",
                 "IsRewarded_T9",
                 "IsRewarded_T10")

EfficacyLag = c("Efficacy_T1",
                 "Efficacy_T2",
                 "Efficacy_T3",
                 "Efficacy_T4",
                 "Efficacy_T5",
                 "Efficacy_T6",
                 "Efficacy_T7",
                 "Efficacy_T8",
                 "Efficacy_T9",
                 "Efficacy_T10")



# Recode and turn into a factor
data.raw = data.raw %>% 
     mutate_at(RewardLag,funs(recode(.,"0" = "NoReward","1" = "Reward"))) %>% 
      mutate_at(RewardLag,funs(factor(.)))

data.raw = data.raw %>% 
     mutate_at("IsRewarded",funs(recode(.,"0" = "NoReward","1" = "Reward"))) %>% 
      mutate_at("IsRewarded",funs(factor(.)))

data.raw = data.raw %>% 
     mutate_at(EfficacyLag,funs(recode(.,"0" = "NoEfficacy","1" = "Efficacy"))) %>% 
      mutate_at(EfficacyLag,funs(factor(.)))

data.raw = data.raw %>% 
     mutate_at("EffLvl",funs(recode(.,"0" = "NoEfficacy","1" = "Efficacy"))) %>% 
      mutate_at("EffLvl",funs(factor(.)))


# Create contrasts for the n-back regression plots
data.raw$IsRewarded = ordered(data.raw$IsRewarded, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T1 = ordered(data.raw$IsRewarded_T1, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T2 = ordered(data.raw$IsRewarded_T2, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T3 = ordered(data.raw$IsRewarded_T3, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T4 = ordered(data.raw$IsRewarded_T4, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T5 = ordered(data.raw$IsRewarded_T5, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T6 = ordered(data.raw$IsRewarded_T6, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T7 = ordered(data.raw$IsRewarded_T7, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T8 = ordered(data.raw$IsRewarded_T8, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T9 = ordered(data.raw$IsRewarded_T9, levels = c("NoReward", "Reward"))
data.raw$IsRewarded_T10 = ordered(data.raw$IsRewarded_T10, levels = c("NoReward", "Reward"))



data.raw$EffLvl = ordered(data.raw$EffLvl, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T1 = ordered(data.raw$Efficacy_T1, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T2 = ordered(data.raw$Efficacy_T2, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T3 = ordered(data.raw$Efficacy_T3, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T4 = ordered(data.raw$Efficacy_T4, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T5 = ordered(data.raw$Efficacy_T5, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T6 = ordered(data.raw$Efficacy_T6, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T7 = ordered(data.raw$Efficacy_T7, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T8 = ordered(data.raw$Efficacy_T8, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T9 = ordered(data.raw$Efficacy_T9, levels = c("NoEfficacy", "Efficacy"))
data.raw$Efficacy_T10 = ordered(data.raw$Efficacy_T10, levels = c("NoEfficacy", "Efficacy"))

# Create previous congruency variable
# data.raw = ddply(data.raw,.(SubID),transform,
#                        Congruency_T1 = append(data.raw$Congruency,NA,after=0)[-(length(data.raw$Congruency)+1)])



#data.raw$Congruency_T1 = append(data.raw$Congruency,NA,after=0)[-(length(data.raw$Congruency)+1)]

# data.raw$Congruency = as.factor(recode(data.raw$Congruency,
#                                 "0" = "Incongruent",
#                                 "1" = "Congruent",
#                                 "2" = "Neutral"))

# data.raw$Congruency_T1 = as.factor(recode(data.raw$Congruency_T1,
#                                 "0" = "Incongruent",
#                                 "1" = "Congruent",
#                                 "2" = "Neutral"))


data.raw = ddply(data.raw,.(SubID),plyr::mutate,
                       Trial = 1:(length(data.raw$RT)/length(unique(data.raw$SubID))))

# create a new variable to account for different drifts that subjects have
data.raw$Drift = ifelse(data.raw$SubID %% 2 == 1, "Odd","Even")
data.raw$Drift = as.factor(data.raw$Drift)

# NA the RTs that have been identified to be with wrong latencies
data.raw$RT[4607] = NA
data.raw$RT[8090] = NA
data.raw$RT[8258] = NA

# # Create the variable with three levels to analyze efficacy and reward feedback taking into account the feedback order
data.raw$Rew_eff_fb[data.raw$feedbackOrder == 1]="RewardUnknown"
data.raw$Rew_eff_fb[data.raw$feedbackOrder == 2 & data.raw$IsRewarded == "Reward"]="Reward"
data.raw$Rew_eff_fb[data.raw$feedbackOrder == 2 & data.raw$IsRewarded == "NoReward"]="NoReward"

data.raw$Eff_rew_fb[data.raw$feedbackOrder == 2]="EfficacyUnknown"
data.raw$Eff_rew_fb[data.raw$feedbackOrder == 1 & data.raw$EffLvl == "Efficacy"]="Efficacy"
data.raw$Eff_rew_fb[data.raw$feedbackOrder == 1 & data.raw$EffLvl == "NoEfficacy"]="NoEfficacy"


#### Import the learning rates for efficacy ###### 
learning_rates = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_efficacy.csv"),header=F,na.strings="NaN")

# add the subject names
learning_rates$SubID = unique(data.raw$SubID)

# rename the variable names
colnames(learning_rates)[1] <- "positive_learning_rate"
colnames(learning_rates)[2] <- "negative_learning_rate"
colnames(learning_rates)[3] <- "initial_bias"
colnames(learning_rates)[4] <- "subject"
colnames(learning_rates)[5] <- "BIC"

# add a new variable in the main dataset in which efficacy is coded as 1 or 0
data.raw$EffLvl_forLR = ifelse(data.raw$EffLvl=="Efficacy",1,0)

##### Calculate the model-based efficacy estimate ######

# for each subject
for (s in 1:length(unique(data.raw$SubID))) {
  # for each trial
  for (t in 1:length(unique(data.raw$Trial))) {
    # if this is the first trial use the inital estimate
    if (t == 1) {
      v = learning_rates$initial_bias[s]
    } else {
      v = v
    }
    
    # save the BIC value
    data.raw$BIC_efficacy[data.raw$SubID == unique(data.raw$SubID)[s] &
                   data.raw$Trial == t] = learning_rates$BIC[s]
    
    # calculate the prediction error for this subject for this trial (difference between the actual and the expected efficacy)
    data.raw$RPE_efficacy[data.raw$SubID == unique(data.raw$SubID)[s] &
                            data.raw$Trial == t] = data.raw$EffLvl_forLR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                                                           data.raw$Trial == t] - v
    
    # if the rpe is positive
    if (data.raw$RPE_efficacy[data.raw$SubID == unique(data.raw$SubID)[s] &
                              data.raw$Trial == t] > 0) {
      
      # calculate the size of the update (the learning rate times the prediction error)
       data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s] * data.raw$RPE_efficacy[data.raw$SubID ==
                                                                                                                               unique(data.raw$SubID)[s] & data.raw$Trial == t]
      # save the absolute value of the update
       data.raw$mbased_efficacy_absolute_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] =  abs(data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t])
       
      # calculate the effiacy estimate (expected efficacy plus the update - the learning rate-weighted prediction error)
      data.raw$mbased_efficacy[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = v + data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # update the value
      v = v + data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # save the learning rate value
      data.raw$LR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s]
      
      # save the positive learning rate value
      data.raw$LR_efficacy_positive[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s]
      
      # if the rpe is negative
    } else {
      
      # calculate the size of the update (the learning rate times the prediction error)
       data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s] * data.raw$RPE_efficacy[data.raw$SubID ==
                                                                                                                               unique(data.raw$SubID)[s] & data.raw$Trial == t]
      # save the absolute value of the update
       data.raw$mbased_efficacy_absolute_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] =  abs(data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t])
       
      # calculate the effiacy estimate (expected efficacy plus the update - the learning rate-weighted prediction error)
      data.raw$mbased_efficacy[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = v + data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # update the value
      v = v + data.raw$mbased_efficacy_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # save the learning rate value
      data.raw$LR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s]
      
      # save the positive learning rate value
      data.raw$LR_efficacy_negative[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s]
    
    }
    
    
  }
}


#### Import the learning rates for reward rate###### 
learning_rates = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_reward.csv"),header=F,na.strings="NaN")
# learning_rates = read.csv(file = here("RL_fitting_only LR","learning_rates_reward.csv"),header=F,na.strings="NaN")


# add the subject names
learning_rates$SubID = unique(data.raw$SubID)

# rename the variable names
colnames(learning_rates)[1] <- "positive_learning_rate"
colnames(learning_rates)[2] <- "negative_learning_rate"
colnames(learning_rates)[3] <- "initial_bias"
colnames(learning_rates)[4] <- "subject"
colnames(learning_rates)[5] <- "BIC"


# add a new variable in the main dataset in which efficacy is coded as 1 or 0
data.raw$IsRewarded_forLR = ifelse(data.raw$IsRewarded=="Reward",1,0)

##### Calculate the model-based reward rate estimate ######

# for each subject
for (s in 1:length(unique(data.raw$SubID))) {
  # for each trial
  for (t in 1:length(unique(data.raw$Trial))) {
    # if this is the first trial use the inital estimate
    if (t == 1) {
      v = learning_rates$initial_bias[s]
    } else {
      v = v
    }
    
    # save the BIC value
    data.raw$BIC_reward[data.raw$SubID == unique(data.raw$SubID)[s] &
                   data.raw$Trial == t] = learning_rates$BIC[s]
    
    # calculate the prediction error for this subject for this trial (difference between the actual and the expected efficacy)
    data.raw$RPE_reward[data.raw$SubID == unique(data.raw$SubID)[s] &
                            data.raw$Trial == t] = data.raw$IsRewarded_forLR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                                                           data.raw$Trial == t] - v
    
    # if the rpe is positive
    if (data.raw$RPE_reward[data.raw$SubID == unique(data.raw$SubID)[s] &
                              data.raw$Trial == t] > 0) {
      
      # calculate the size of the update (the learning rate times the prediction error)
       data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s] * data.raw$RPE_reward[data.raw$SubID ==
                                                                                                                               unique(data.raw$SubID)[s] & data.raw$Trial == t]
      # save the absolute value of the update
       data.raw$mbased_reward_absolute_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] =  abs(data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t])
       
      # calculate the reward estimate (expected reward plus the update - the learning rate-weighted prediction error)
      data.raw$mbased_reward[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = v + data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # update the value
      v = v + data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # save the learning rate value
      data.raw$LR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s]
      
      # save the positive learning rate value
      data.raw$LR_reward_positive[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$positive_learning_rate[s]
      
      # if the rpe is negative
    } else {
      
      # calculate the size of the update (the learning rate times the prediction error)
       data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s] * data.raw$RPE_reward[data.raw$SubID ==
                                                                                                                               unique(data.raw$SubID)[s] & data.raw$Trial == t]
      # save the absolute value of the update
       data.raw$mbased_reward_absolute_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] =  abs(data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t])
       
      # calculate the reward estimate (expected efficacy plus the update - the learning rate-weighted prediction error)
      data.raw$mbased_reward[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = v + data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # update the value
      v = v + data.raw$mbased_reward_update[data.raw$SubID == unique(data.raw$SubID)[s] & data.raw$Trial == t]
      
      # save the learning rate value
      data.raw$LR[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s]
      
      # save the positive learning rate value
      data.raw$LR_reward_negative[data.raw$SubID == unique(data.raw$SubID)[s] &
                                 data.raw$Trial == t] = learning_rates$negative_learning_rate[s]
    
    }
    
    
  }
}


# Create a previous value variable (for predicting everything before the new feedback participants rely on the value from the previous trial)
data.raw = ddply(data.raw,.(SubID),transform,
                   mbased_reward_prev = append(mbased_reward,NA,after=0)[-(length(mbased_reward)+1)],
                   mbased_efficacy_prev = append(mbased_efficacy,NA,after=0)[-(length(mbased_efficacy)+1)])

```
### EEG

```{r}

#### Late CNV (1000 - 1500msms after fix cross onset)
CNV10001500 = readMat(here("Data/Experiment1/EEG/preprocessed","CNV10001500.mat"))

CNV10001500 = as.data.frame(CNV10001500) # convert to data frame

colnames(CNV10001500)[c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 
                         16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
                         31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
                         46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
                         61, 62, 63, 64, 65)]=
  
  c('Fp1', 'Fpz', 'Fp2', 'AF3', 'AFz', 'AF4', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',
    'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'T7', 'C5', 'C3', 'C1',
    'C2', 'C4', 'C6', 'T8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10',
    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO3', 'POz', 'PO4', 'O1', 'Oz', 'O2',
    'LO1', 'IO1', 'IO2', 'LO2', 'Cz')
# 
data.raw$CNV10001500 = apply(cbind (CNV10001500$Fz,CNV10001500$F1,CNV10001500$F2,
                                    CNV10001500$FCz,CNV10001500$FC1,CNV10001500$FC2,
                                    CNV10001500$Cz,CNV10001500$C1,CNV10001500$C2), 1, mean) # add the average activation in ROI to the behaviroal dataset






#### P3b to the efficacy feedback (350 - 500ms after feedback onset) 
P3bE350500 = readMat(here("Data/Experiment1/EEG/preprocessed","P3bE350500.mat"))

P3bE350500 = as.data.frame(P3bE350500) # convert to data frame

colnames(P3bE350500)[c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 
                        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
                        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
                        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
                        61, 62, 63, 64, 65)]=
  
  c('Fp1', 'Fpz', 'Fp2', 'AF3', 'AFz', 'AF4', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',
    'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'T7', 'C5', 'C3', 'C1',
    'C2', 'C4', 'C6', 'T8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10',
    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO3', 'POz', 'PO4', 'O1', 'Oz', 'O2',
    'LO1', 'IO1', 'IO2', 'LO2', 'Cz')


data.raw$P3bE350500 = apply(cbind (P3bE350500$Pz,P3bE350500$P1,P3bE350500$P2,
                                   P3bE350500$POz,P3bE350500$PO3,P3bE350500$PO4,
                                   P3bE350500$CPz,P3bE350500$CP1,P3bE350500$CP2), 1, mean) # add the average activation in ROI to the behaviroal dataset

#### P3b to the efficacy feedback for the control analysis (200 - 300ms after feedback onset) 
P3bEcontrol200300 = readMat(here("Data/Experiment1/EEG/preprocessed","P3bEcontrol200300.mat"))



P3bEcontrol200300 = as.data.frame(P3bEcontrol200300) # convert to data frame

colnames(P3bEcontrol200300)[c( 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 
                        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
                        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
                        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
                        61, 62, 63, 64, 65)]=
  
  c('Fp1', 'Fpz', 'Fp2', 'AF3', 'AFz', 'AF4', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',
    'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'T7', 'C5', 'C3', 'C1',
    'C2', 'C4', 'C6', 'T8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10',
    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO3', 'POz', 'PO4', 'O1', 'Oz', 'O2',
    'LO1', 'IO1', 'IO2', 'LO2', 'Cz')


data.raw$P3bEcontrol200300 = apply(cbind (P3bEcontrol200300$Pz,P3bEcontrol200300$P1,P3bEcontrol200300$P2,
                                          P3bEcontrol200300$POz,P3bEcontrol200300$PO3,P3bEcontrol200300$PO4,
                                   P3bEcontrol200300$CPz,P3bEcontrol200300$CP1,P3bEcontrol200300$CP2), 1, mean) # add the average activation in ROI to the behaviroal dataset




```

## Parameters used in the analysis

Window for the running average efficacy calculation is  `r unique(data.raw$RunAvgWindow_Eff)`

Window for the running average reward calculation is  `r unique(data.raw$RunAvgWindow_Rew)`

## Prepare data

```{r}
#Add smooth variables and the ground truth-estimate correlation
 data =data.raw
  data =  data %>%
     group_by(SubID)%>%
     mutate(
       Accuracy_smooth = rollapply(Acc,list(seq(-5, -1)),mean, fill = NA, na.rm = TRUE, align = "right"),
       RT_smooth = rollapply(AccRT,list(seq(-5, -1)),mean, fill = NA, na.rm = TRUE, align = "right"),
       Spearman_r_eff=rcorr(ReportedEfficacyLin, runAvgEfficacy, type = "spearman")$r[1,2],
       Spearman_r_rew_rate=rcorr(ReportedRewRateLin, runAvgRewRate, type = "spearman")$r[1,2])

# Exclude subjects with negative correlations
# missing_eeg = c(1070, 1054)
# data = data[!data$SubID %in% missing_eeg,]
  
```

The number of subjects is is `r length(unique(data$SubID))`

The number of NAs in the RTs is `r sum(is.na(data$RT))`

```{r}
# delete RTs below 200mms
#data = data.raw
data$RT = ifelse(data$RT<200,NA,data$RT)
```

Without RTs<200ms the number of NAs in the RTs is `r sum(is.na(data$RT))`

The number of NAs in the RTs is `r sum(is.na(data$Acc))`


## Descriptive stats 

```{r, warning=FALSE, message=FALSE, results='asis'}
# For each subject separately

  #Summary stats table 
summary_table = ddply(data,.(Congruency),plyr::summarize,
                                       MeanRT=mean(RT,na.rm=TRUE), # mean RT per condition
                                       SDRT=sd(RT,na.rm=TRUE),
                                       MeanAcc=mean(Acc,na.rm=TRUE), 
                                       SDAcc=sd(Acc,na.rm=TRUE),
                                       RewardRate = count(IsRewarded)[[2,2]]/(count(IsRewarded)[[2,2]]+count(IsRewarded)[[1,2]]),
                                       Efficacy = count(EffLvl)[[1,2]]/(count(EffLvl)[[2,2]]+count(EffLvl)[[1,2]]))

print(kable(summary_table, align="l", caption="Descriptive stats"))

  #Summary stats table 
summary_table = ddply(data,.(SubID),plyr::summarize,
                                       MeanRT=mean(RT,na.rm=TRUE), # mean RT per condition
                                       SDRT=sd(RT,na.rm=TRUE),
                                       MeanAcc=mean(Acc,na.rm=TRUE), 
                                       SDAcc=sd(Acc,na.rm=TRUE),
                                       RewardRate = count(IsRewarded)[[2,2]]/(count(IsRewarded)[[2,2]]+count(IsRewarded)[[1,2]]),
                                       Efficacy = count(EffLvl)[[1,2]]/(count(EffLvl)[[2,2]]+count(EffLvl)[[1,2]]))

print(kable(summary_table, align="l", caption="Descriptive stats"))

  #Summary stats table per participant
# summary_table = ddply(data,.(SubID,Congruency),plyr::summarize,
#                                        MeanRT=mean(RT,na.rm=TRUE), # mean RT per condition
#                                        SDRT=sd(RT,na.rm=TRUE),
#                                        MeanAcc=mean(Acc,na.rm=TRUE),
#                                        SDAcc=sd(Acc,na.rm=TRUE),
#                                        RewardRate = count(IsRewarded)[[2,2]]/(count(IsRewarded)[[2,2]]+count(IsRewarded)[[1,2]]),
#                                        Efficacy = count(EffLvl)[[1,2]]/(count(EffLvl)[[2,2]]+count(EffLvl)[[1,2]]))
# 
# print(kable(summary_table, align="l", caption="Descriptive stats"))

# Summary design table
summary_table = ddply(data,.(Congruency,IsRewarded,EffLvl),plyr::summarize,
                                       N=length(Acc)/length(unique(SubID)))
print(kable(summary_table, align="l", caption="Design check"))

```



```{r, fig.width=12, fig.height=6, results="axis"}
## Efficacy plots for each subject for each drift
# For each subject separately
# for (subject in 1:length(unique(data$SubID))) {
#   #Plotting
#   plot_data = subset(data,data$SubID == unique(data.raw$SubID)[subject])
# 
# 
#     # Efficacy
# 
#     efficacy_plot = ggplot(data = plot_data, aes(x = plot_data$Trial),colour = efficacyDrift)+
#       geom_line(mapping=aes(y=plot_data$ReportedEfficacy_Drift1Lin,color='Estimated drift1')) +
#       geom_line(mapping=aes(y=plot_data$ReportedEfficacy_Drift2Lin,color='Estimated drift2')) +
#       geom_point(mapping=aes(y=plot_data$EfficacyProbeResp_Drift1,color='Actual points drift 1')) +
#       geom_point(mapping=aes(y=plot_data$EfficacyProbeResp_Drift2,color='Actual points drift 2')) +
#       ggtitle(paste0('Efficacy estimates - Subject ',subject)) +
#       scale_color_manual(values = c(
#       'Estimated drift1' = 'blue',
#       'Estimated drift2' = 'red',
#       'Actual points drift 1' = 'green',
#       'Actual points drift 2' = 'blue')) +
#       labs(color = 'Efficacy')+
#       theme_classic() +
#       xlab("Trial") +
#       ylab("Real efficacy") +
#       ylim(0,1.2) +
#       labs("True efficacy", "Estimated")
#   
# 
#  
#   print(efficacy_plot)
# }


```

## Checking the efficacy learning model


### N trials back by reward

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

model = readRDS("model.efficacy.by.previous.reward_5.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# EffLvlNEff_min_Eff 
t = hypothesis(model,"EffLvlNEff_min_Eff <0")
estimates[2] = t$hypothesis$Post.Prob

# Efficacy_T12M1 
t = hypothesis(model,"Efficacy_T12M1 <0")
estimates[3] = t$hypothesis$Post.Prob

# Efficacy_T22M1 
t = hypothesis(model,"Efficacy_T22M1 <0")
estimates[4] = t$hypothesis$Post.Prob

# Efficacy_T22M1 
t = hypothesis(model,"Efficacy_T32M1 <0")
estimates[5] = t$hypothesis$Post.Prob

# Efficacy_T42M1 
t = hypothesis(model,"Efficacy_T42M1 <0")
estimates[6] = t$hypothesis$Post.Prob

# IsRewardedRew_min_NRew 
t = hypothesis(model,"IsRewardedRew_min_NRew <0")
estimates[7] = t$hypothesis$Post.Prob

# IsRewarded_T12M1 
t = hypothesis(model,"IsRewarded_T12M1 <0")
estimates[8] = t$hypothesis$Post.Prob

# IsRewarded_T22M1 
t = hypothesis(model,"IsRewarded_T22M1 <0")
estimates[9] = t$hypothesis$Post.Prob

# IsRewarded_T32M1 
t = hypothesis(model,"IsRewarded_T32M1 <0")
estimates[10] = t$hypothesis$Post.Prob

# IsRewarded_T42M1 
t = hypothesis(model,"IsRewarded_T42M1 <0")
estimates[11] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept=0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# EffLvlNEff_min_Eff 
t = hypothesis(model,"EffLvlNEff_min_Eff=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T12M1 
t = hypothesis(model,"Efficacy_T12M1=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T12M1 
t = hypothesis(model,"Efficacy_T22M1=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T22M1 
t = hypothesis(model,"Efficacy_T32M1=0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T42M1 
t = hypothesis(model,"Efficacy_T42M1=0")
estimates[6] = 1/(t$hypothesis$Evid.Ratio)

# IsRewardedRew_min_NRew 
t = hypothesis(model,"IsRewardedRew_min_NRew=0")
estimates[7] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T12M1 
t = hypothesis(model,"IsRewarded_T12M1=0")
estimates[8] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T22M1 
t = hypothesis(model,"IsRewarded_T22M1=0")
estimates[9] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T32M1 
t = hypothesis(model,"IsRewarded_T32M1=0")
estimates[10] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T42M1 
t = hypothesis(model,"IsRewarded_T42M1=0")
estimates[11] = 1/(t$hypothesis$Evid.Ratio)


# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```

Plot

```{r,warning=FALSE, message=FALSE}


# Plot
# Plot

# pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS1_A2.pdf")
# 
# p = stanplot(model, pars = c("^b_IsRewarded",
#                                         "^b_IsRewarded_T12M1",
#                                         "^b_IsRewarded_T22M1",
#                                         "^b_IsRewarded_T32M1",
#                                         "^b_IsRewarded_T42M1",
#                              "^b_EffLvlNEff_min_Eff",
#                                         "^b_Efficacy_T12M1",
#                                         "^b_Efficacy_T22M1",
#                                         "^b_Efficacy_T32M1",
#                                         "^b_Efficacy_T42M1")) 
# 
# 
# 
#   
# p = p +  scale_y_discrete(labels= c(
#             "t-4 Efficacy",
#           "t-3 Efficacy",
#           "t-2 Efficacy",
#           "t-1 Efficacy",
#           "t Efficacy",
#           "t-4 Reward",
#           "t-3 Reward",
#           "t-2 Reward",
#           "t-1 Reward",
#           "t Reward"),limits = rev(levels(p[["data"]][["parameter"]]))) +
#   
#   geom_vline(xintercept=0, linetype="dashed", color = "black") +
#   
#   labs(x = "Regression estimate", y = "Feedback\n") + 
#   scale_x_continuous(limits = c(-0.05,0.23),breaks=seq(-0.05, 0.25, by = 0.05)) + 
# 
#   
#   # ggtitle("Predicting reported efficacy\n") + 
# 
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(), 
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 18,family = ""),
#               axis.text.x=element_text(colour="black", size = 18,family = ""),
#               axis.text.y=element_text(colour="black", size = 18,family = "", face = "plain",hjust=0),
#               axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))
#   
# f.2.a=p
# p
# dev.off()
# 
# p

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure2A_NewNew.pdf")

p = stanplot(model, pars = c("^b_IsRewarded",
                                        "^b_IsRewarded_T12M1",
                                        "^b_IsRewarded_T22M1",
                                        "^b_IsRewarded_T32M1",
                                        "^b_IsRewarded_T42M1",
                             "^b_EffLvlNEff_min_Eff",
                                        "^b_Efficacy_T12M1",
                                        "^b_Efficacy_T22M1",
                                        "^b_Efficacy_T32M1",
                                        "^b_Efficacy_T42M1")) + coord_flip()



  
p = p +  scale_y_discrete(labels= c(
            "t-4",
          "t-3",
          "t-2",
          "t-1",
          "t",
          "t-4",
          "t-3",
          "t-2",
          "t-1",
          "t"),limits = rev(levels(p[["data"]][["parameter"]]))) +
  
  geom_vline(xintercept=0, linetype="dashed", color = "black") +
  # geom_hline(yintercept=4, color = "black") +
  
  labs(x = "Regression estimate", y = "Feedback\n") + 
  scale_x_continuous(limits = c(-0.05,0.23),breaks=seq(-0.05, 0.25, by = 0.05)) + 

  
  # ggtitle("Predicting reported efficacy\n") + 

  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18,family = "", face = "plain",hjust=0),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))
  
f.2.a=p
p
dev.off()

p

# plot only efficacy

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure2_A.pdf")

p = stanplot(model, pars = c("^b_EffLvlNEff_min_Eff",
                                        "^b_Efficacy_T12M1",
                                        "^b_Efficacy_T22M1",
                                        "^b_Efficacy_T32M1",
                                        "^b_Efficacy_T42M1"))
  
p = p +  scale_y_discrete(labels= c(
            "t-4",
          "t-3",
          "t-2",
          "t-1",
          "t"
          ),limits = rev(levels(p[["data"]][["parameter"]]))) +
  
  geom_vline(xintercept=0, linetype="dashed", color = "black") +
  
  labs(x = "Regression estimate", y = "Feedback\n") + 
  scale_x_continuous(limits = c(-0.05,0.23),breaks=seq(-0.05, 0.25, by = 0.05)) + 

  
  # ggtitle("Predicting reported efficacy\n") + 

  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 25,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 20),
              axis.text.x=element_text(colour="black", size = 20),
              axis.text.y=element_text(colour="black", size = 20, face = "plain",hjust=0),
              axis.title=element_text(size=24,colour = "black",vjust = 1),
        )

p
dev.off()

p

```


### Predicting the subjective estimates

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

model = readRDS("model.efficacy.subest_by_modelbased.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# Efficacy
t = hypothesis(model,"mbased_reward <0")
estimates[2] = t$hypothesis$Post.Prob

# Efficacy_T12M1 
t = hypothesis(model,"mbased_efficacy <0")
estimates[3] = t$hypothesis$Post.Prob



# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept=0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# Reward
t = hypothesis(model,"mbased_reward=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy 
t = hypothesis(model,"mbased_efficacy=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```

Bayes R2
```{r, warning=FALSE, message=FALSE}
bayes_R2(model)
```

Plot

```{r,warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "mbased_efficacy",plot=FALSE)
# pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_C.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        xlab("Model-based efficacy estimate")+
        ylab(expression(paste("Subjective efficacy estimate")))+
  scale_x_continuous(labels = scaleFUN)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p

p = marginal_effects(model, effects = "mbased_reward",plot=FALSE)
# pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_C.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        xlab("Model-based reward estimate")+
        ylab(expression(paste("Subjective reward estimate")))+
  scale_x_continuous(labels = scaleFUN)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p


```


### Learning rates

```{r,warning=FALSE, message=FALSE}

#### Import the learning rates for efficacy ###### 

learning_rates_efficacy = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_efficacy.csv"),header=F,na.strings="NaN")


# add the subject names
learning_rates_efficacy$SubID = unique(data.raw$SubID)

# rename the variable names
colnames(learning_rates_efficacy)[1] <- "positive_learning_rate"
colnames(learning_rates_efficacy)[2] <- "negative_learning_rate"
colnames(learning_rates_efficacy)[3] <- "initial_bias"
colnames(learning_rates_efficacy)[4] <- "subject"


# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
# names(myColors) = levels(data$Congruency)
# colScale = scale_colour_manual(name = "Congruency",values = myColors)
barfill <- "#4271AE"
barlines <- "#1F3552"

# Positive efficacy learning rates 
p =ggplot(learning_rates_efficacy, aes(positive_learning_rate)) + 
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) + 
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) + 
        geom_vline(xintercept=mean(learning_rates_efficacy$positive_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$positive_learning_rate),digits = 2))),size=5) + 


        labs(x = "Positive learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


# Negative efficacy learning rates 
p =ggplot(learning_rates_efficacy, aes(negative_learning_rate)) + 
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) + 
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) + 
        geom_vline(xintercept=mean(learning_rates_efficacy$negative_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$negative_learning_rate),digits = 2))),size=5) + 


        labs(x = "Negative learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure2_C.pdf")


# Positive vs. negative LRs 
p =ggplot(learning_rates_efficacy, aes(positive_learning_rate,negative_learning_rate)) + 
        geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) + 
        scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) + 
        geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
        ylim(0,0.4)+
  xlim(0,0.4)+


        labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))

f.2.c = p
p
dev.off()

p


### Learning rates for efficacy for two drifts ######

# Odd participants

learning_rates_efficacy = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_efficacy.csv"),header=F,na.strings="NaN")



# add the subject names
learning_rates_efficacy$SubID = unique(data.raw$SubID)

learning_rates_efficacy$drift = ifelse(learning_rates_efficacy$SubID %% 2 ==0,"even","odd")


# rename the variable names
colnames(learning_rates_efficacy)[1] <- "positive_learning_rate"
colnames(learning_rates_efficacy)[2] <- "negative_learning_rate"
colnames(learning_rates_efficacy)[3] <- "initial_bias"
colnames(learning_rates_efficacy)[4] <- "subject"

learning_rates_efficacy = subset(learning_rates_efficacy,drift=="odd")


# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
# names(myColors) = levels(data$Congruency)
# colScale = scale_colour_manual(name = "Congruency",values = myColors)
barfill <- "#4271AE"
barlines <- "#1F3552"

# Positive efficacy learning rates
p =ggplot(learning_rates_efficacy, aes(positive_learning_rate)) +
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        ggtitle("Learning rates - Odd subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
        geom_vline(xintercept=mean(learning_rates_efficacy$positive_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$positive_learning_rate),digits = 3))),size=5) +


        labs(x = "Positive learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p

f.1 = p

# Negative efficacy learning rates
p =ggplot(learning_rates_efficacy, aes(negative_learning_rate)) +
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        ggtitle("Learning rates - Odd subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
        geom_vline(xintercept=mean(learning_rates_efficacy$negative_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$negative_learning_rate),digits = 3))),size=5) +


        labs(x = "Negative learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p

f.2 = p
# Positive vs. negative LRs

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS2_B.pdf")

p =ggplot(learning_rates_efficacy, aes(positive_learning_rate,negative_learning_rate)) +
        geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rate bias - Odd subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
        scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
        geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
        ylim(0,0.4)+
  xlim(0,0.4)+


        labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))

f.3 = p
p

dev.off()

p


# Even participants


learning_rates_efficacy = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_efficacy.csv"),header=F,na.strings="NaN")



# add the subject names
learning_rates_efficacy$SubID = unique(data.raw$SubID)

learning_rates_efficacy$drift = ifelse(learning_rates_efficacy$SubID %% 2 ==0,"even","odd")


# rename the variable names
colnames(learning_rates_efficacy)[1] <- "positive_learning_rate"
colnames(learning_rates_efficacy)[2] <- "negative_learning_rate"
colnames(learning_rates_efficacy)[3] <- "initial_bias"
colnames(learning_rates_efficacy)[4] <- "subject"

learning_rates_efficacy = subset(learning_rates_efficacy,drift=="even")


# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
# names(myColors) = levels(data$Congruency)
# colScale = scale_colour_manual(name = "Congruency",values = myColors)
barfill <- "#4271AE"
barlines <- "#1F3552"

# Positive efficacy learning rates
p =ggplot(learning_rates_efficacy, aes(positive_learning_rate)) +
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        ggtitle("Learning rates - Even subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
        geom_vline(xintercept=mean(learning_rates_efficacy$positive_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$positive_learning_rate),digits = 3))),size=5) +


        labs(x = "Positive learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p

f.4 = p

# Negative efficacy learning rates
p =ggplot(learning_rates_efficacy, aes(negative_learning_rate)) +
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        ggtitle("Learning rates - Even subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
        geom_vline(xintercept=mean(learning_rates_efficacy$negative_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_efficacy$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$negative_learning_rate),digits = 3))),size=5) +


        labs(x = "Negative learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p
f.5 = p

# Positive vs. negative LRs

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS2_D.pdf")

p =ggplot(learning_rates_efficacy, aes(positive_learning_rate,negative_learning_rate)) +
        geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rate bias - Even subjects") +
        theme_bw() +
        scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
        scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
        geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
        ylim(0,0.4)+
  xlim(0,0.4)+


        labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))

f.6 = p
p

dev.off()

p


# # Figure 2
# tiff("C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/Collaborations/DCNLab/LFXC_Shared_DA/analysis/Scripts/Learning Models/Efficacy_simulations_Ivan/Parameter Recovery/Figure2.tiff", units="in", width=20, height=20, res=200)



# 
# x = ggdraw(xlim = c(0,1.5),ylim = c(0,2)) +
#     draw_plot(f.1, x = 0.03, y = 0.50, width = 0.45, height = 0.45) +
#     draw_plot(f.2, x = 0.53, y = 0.50, width = 0.45, height = 0.45) +
#     draw_plot(f.3, x = 1.03, y = 0.50, width = 0.45, height = 0.45) +
# 
#     draw_plot(f.4, x = 0.03, y = 0.00, width = 0.45, height = 0.45) +
#     draw_plot(f.5, x = 0.53, y = 0.00, width = 0.45, height = 0.45) +
#     draw_plot(f.6, x = 1.03, y = 0.00, width = 0.45, height = 0.45) +
# 
#   draw_plot_label(label = c("A", "B", "C","D", "E","F"), size = 20,
#                   x = c(0, 0.50, 1.00,0, 0.50, 1.00), y = c(1, 1,1, 0.50,0.50,0.50))
# x
# 
# dev.off()




# #### Simulated Learning rates for efficacy for two drifts ######
# 
# # Odd participants
# 
# learning_rates_efficacy = read.csv(file = "C:/Users/igrahek/Dropbox (Brown)/Ivan/Studies/EVC fitting/Efficacy_simulations/Parameter Recovery/results/learning_rates_efficacy_odd.csv",header=F,na.strings="NaN")
# 
# 
# 
# # add the subject names
# learning_rates_efficacy$SubID = unique(data.raw$SubID)
# 
# 
# 
# # rename the variable names
# colnames(learning_rates_efficacy)[1] <- "positive_learning_rate"
# colnames(learning_rates_efficacy)[2] <- "negative_learning_rate"
# colnames(learning_rates_efficacy)[3] <- "initial_bias"
# colnames(learning_rates_efficacy)[4] <- "subject"
# 
# 
# 
# # Set parameters for plots
# set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
# myColors = brewer.pal(3,"Set2") #colors
# # names(myColors) = levels(data$Congruency)
# # colScale = scale_colour_manual(name = "Congruency",values = myColors)
# barfill <- "#4271AE"
# barlines <- "#1F3552"
# 
# # Positive efficacy learning rates
# p =ggplot(learning_rates_efficacy, aes(positive_learning_rate)) +
#         geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rates - Odd subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
#         scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
#         geom_vline(xintercept=mean(learning_rates_efficacy$positive_learning_rate), linetype="dashed", color = "black") +
#         geom_text(x=mean(learning_rates_efficacy$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$positive_learning_rate),digits = 3))),size=5) +
# 
# 
#         labs(x = "Positive learning rate", y = "Count\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# p
# 
# f.1 = p
# 
# # Negative efficacy learning rates
# p =ggplot(learning_rates_efficacy, aes(negative_learning_rate)) +
#         geom_histogram(colour = barlines, fill = barfill,binwidth = 0.0051)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rates - Odd subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
#         scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
#         geom_vline(xintercept=mean(learning_rates_efficacy$negative_learning_rate), linetype="dashed", color = "black") +
#         geom_text(x=mean(learning_rates_efficacy$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$negative_learning_rate),digits = 3))),size=5) +
# 
# 
#         labs(x = "Negative learning rate", y = "Count\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# p
# 
# f.2 = p
# # Positive vs. negative LRs
# p =ggplot(learning_rates_efficacy, aes(positive_learning_rate,negative_learning_rate)) +
#         geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rate bias - Odd subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
#         scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
#         geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
#         ylim(0,0.4)+
#   xlim(0,0.4)+
# 
# 
#         labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# 
# f.3 = p
# p
# 
# 
# # Even participants
# 
# learning_rates_efficacy = read.csv(file = "C:/Users/igrahek/Dropbox (Brown)/Ivan/Studies/EVC fitting/Efficacy_simulations/Parameter Recovery/results/learning_rates_efficacy_even.csv",header=F,na.strings="NaN")
# 
# 
# 
# # add the subject names
# learning_rates_efficacy$SubID = unique(data.raw$SubID)
# 
# learning_rates_efficacy$drift = ifelse(learning_rates_efficacy$SubID %% 2 ==0,"even","odd")
# 
# 
# # rename the variable names
# colnames(learning_rates_efficacy)[1] <- "positive_learning_rate"
# colnames(learning_rates_efficacy)[2] <- "negative_learning_rate"
# colnames(learning_rates_efficacy)[3] <- "initial_bias"
# colnames(learning_rates_efficacy)[4] <- "subject"
# 
# learning_rates_efficacy = subset(learning_rates_efficacy,drift=="even")
# 
# 
# # Set parameters for plots
# set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
# myColors = brewer.pal(3,"Set2") #colors
# # names(myColors) = levels(data$Congruency)
# # colScale = scale_colour_manual(name = "Congruency",values = myColors)
# barfill <- "#4271AE"
# barlines <- "#1F3552"
# 
# # Positive efficacy learning rates
# p =ggplot(learning_rates_efficacy, aes(positive_learning_rate)) +
#         geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rates - Even subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
#         scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
#         geom_vline(xintercept=mean(learning_rates_efficacy$positive_learning_rate), linetype="dashed", color = "black") +
#         geom_text(x=mean(learning_rates_efficacy$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$positive_learning_rate),digits = 3))),size=5) +
# 
# 
#         labs(x = "Positive learning rate", y = "Count\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# p
# 
# f.4 = p
# 
# # Negative efficacy learning rates
# p =ggplot(learning_rates_efficacy, aes(negative_learning_rate)) +
#         geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rates - Even subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) +
#         scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) +
#         geom_vline(xintercept=mean(learning_rates_efficacy$negative_learning_rate), linetype="dashed", color = "black") +
#         geom_text(x=mean(learning_rates_efficacy$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_efficacy$negative_learning_rate),digits = 3))),size=5) +
# 
# 
#         labs(x = "Negative learning rate", y = "Count\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# p
# f.5 = p
# 
# # Positive vs. negative LRs
# p =ggplot(learning_rates_efficacy, aes(positive_learning_rate,negative_learning_rate)) +
#         geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
#         ggtitle("Simulation: Learning rate bias - Even subjects") +
#         theme_bw() +
#         scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
#         scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) +
#         geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
#         ylim(0,0.4)+
#   xlim(0,0.4)+
# 
# 
#         labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
#   theme(axis.line = element_line(size=1, colour = "black"),
#             panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#             panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# 
# f.6 = p
# p
# 
# 
# # Figure 2
# tiff("C:/Users/igrahek/Dropbox (Brown)/Ivan/Studies/EVC fitting/Efficacy_simulations/Parameter Recovery/results/Figure2_sumulated.tiff", units="in", width=20, height=20, res=200)
# 
# 
# 
# x = ggdraw(xlim = c(0,1.5),ylim = c(0,2)) +
#     draw_plot(f.1, x = 0.03, y = 0.50, width = 0.45, height = 0.45) +
#     draw_plot(f.2, x = 0.53, y = 0.50, width = 0.45, height = 0.45) +
#     draw_plot(f.3, x = 1.03, y = 0.50, width = 0.45, height = 0.45) +
# 
#     draw_plot(f.4, x = 0.03, y = 0.00, width = 0.45, height = 0.45) +
#     draw_plot(f.5, x = 0.53, y = 0.00, width = 0.45, height = 0.45) +
#     draw_plot(f.6, x = 1.03, y = 0.00, width = 0.45, height = 0.45) +
# 
#   draw_plot_label(label = c("A", "B", "C","D", "E","F"), size = 20,
#                   x = c(0, 0.50, 1.00,0, 0.50, 1.00), y = c(1, 1,1, 0.50,0.50,0.50))
# x
# 
# dev.off()
# 
# 

```

### Statistical comparison of the learning rates for all subjects
#### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.ttest.learning_rates_efficacy.rds")

```



#### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "HDI (95%)"),align = "lrrrr")
```

#### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "Learning_rate_type",plot=FALSE)

p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("Learning rate type")))+
        ylab(paste("Learning rate"))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


```


#### Inference about the model


Check the LR difference

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_Learning_rate_type2M1"]]

hypothesis(model,"Learning_rate_type2M1  >0")


plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

BF for the LR difference

```{r, warning=FALSE, message=FALSE}


hypothesis(model,"Learning_rate_type2M1  =0")


```





### Statistical comparison of the learning rates for even subjects
#### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.ttest.learning_rates_efficacy_even_subs.rds")

```



#### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "HDI (95%)"),align = "lrrrr")
```

#### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "Learning_rate_type",plot=FALSE)

p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("Learning rate type")))+
        ylab(paste("Learning rate"))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


```


#### Inference about the model


Check the LR difference effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_Learning_rate_type2M1"]]

hypothesis(model,"Learning_rate_type2M1  >0")


plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

BF for the LR difference

```{r, warning=FALSE, message=FALSE}


hypothesis(model,"Learning_rate_type2M1  =0")


```





### Statistical comparison of the learning rates for odd subjects
#### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.ttest.learning_rates_efficacy_odd_subs.rds")

```



#### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "HDI (95%)"),align = "lrrrr")
```

#### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "Learning_rate_type",plot=FALSE)

p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("Learning rate type")))+
        ylab(paste("Learning rate"))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


```


#### Inference about the model


Check the LR difference

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_Learning_rate_type2M1"]]

hypothesis(model,"Learning_rate_type2M1  >0")


plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

BF for the LR difference

```{r, warning=FALSE, message=FALSE}


hypothesis(model,"Learning_rate_type2M1  =0")


```



### Average R2 for the learning model
```{r,warning=FALSE, message=FALSE}

###### Calculate the average R2 #####

### Efficacy
data.efficacy = subset(data,is.na(EfficacyProbeResp)!=1)

# Calculate the mean efficacy probe response per subject
MeanEffProbe=mean(data.efficacy$EfficacyProbeResp,na.rm=TRUE)

# Calculate the SSE total
SSE.total = sum((data.efficacy$EfficacyProbeResp - MeanEffProbe)^2)

# Calculate the SSE residual
SSE.residual = sum((data.efficacy$EfficacyProbeResp - data.efficacy$mbased_efficacy)^2) # Same as in Matlab

# Calculate the R2
R2.efficacy = 1 - SSE.residual/SSE.total


```



R2 for efficacy is  `r R2.efficacy`




### Per subject R2 for the learning model

```{r,warning=FALSE, message=FALSE}

###### Calculate the R2 per subject #####

# Initialize the dataframe
R2 = zeros(length(unique(data$SubID)),2)
colnames(R2) = c("SubID","Efficacy_R2")
R2 = as.data.frame(R2)


# For each subject
for (s in 1:length(unique(data$SubID))) {
  # Save the subject number
  R2$SubID[s] = unique(data.raw$SubID)[s]
  
  
  ### Efficacy
  data.efficacy = subset(data, is.na(EfficacyProbeResp) != 1 &data$SubID == unique(data.raw$SubID)[s])
  
  # Calculate the mean efficacy probe response per subject
  MeanEffProbe=mean(data.efficacy$EfficacyProbeResp,na.rm=TRUE)

  # Calculate the SSE total
  SSE.total = sum((data.efficacy$EfficacyProbeResp - MeanEffProbe)^2)
  
  # Calculate the SSE residual
  SSE.residual = sum((data.efficacy$EfficacyProbeResp - data.efficacy$mbased_efficacy) ^ 2)
  
  # Calculate the R2
  R2$Efficacy_R2[s] = 1 - SSE.residual / SSE.total
  
  
  
}


kable(R2)

hist(R2$Efficacy_R2)

```




### Average R2 for the 5-running average
```{r,warning=FALSE, message=FALSE}

###### Calculate the average R2 #####

### Efficacy
data.efficacy = subset(data,is.na(EfficacyProbeResp)!=1)

# Calculate the mean efficacy probe response per subject
MeanEffProbe=mean(data.efficacy$EfficacyProbeResp,na.rm=TRUE)

# Calculate the SSE total
SSE.total = sum((data.efficacy$EfficacyProbeResp - MeanEffProbe)^2)

# Calculate the SSE residual
SSE.residual = sum((data.efficacy$EfficacyProbeResp - data.efficacy$runAvgEfficacy)^2)

# Calculate the R2
R2.efficacy = 1 - SSE.residual/SSE.total



```



R2 for efficacy is  `r R2.efficacy`



### Per subject R2 for the 5-running average

```{r,warning=FALSE, message=FALSE}

###### Calculate the R2 per subject #####

# Initialize the dataframe
R2 = zeros(length(unique(data$SubID)),2)
colnames(R2) = c("SubID","Efficacy_R2")
R2 = as.data.frame(R2)


# For each subject
for (s in 1:length(unique(data$SubID))) {
  # Save the subject number
  R2$SubID[s] = unique(data.raw$SubID)[s]
  
  
  ### Efficacy
  data.efficacy = subset(data, is.na(EfficacyProbeResp) != 1 &data$SubID == unique(data.raw$SubID)[s])
  
  # Calculate the mean efficacy probe response per subject
  MeanEffProbe=mean(data.efficacy$EfficacyProbeResp,na.rm=TRUE)

  # Calculate the SSE total
  SSE.total = sum((data.efficacy$EfficacyProbeResp - MeanEffProbe)^2)
  
  # Calculate the SSE residual
  SSE.residual = sum((data.efficacy$EfficacyProbeResp - data.efficacy$runAvgEfficacy) ^ 2)
  
  # Calculate the R2
  R2$Efficacy_R2[s] = 1 - SSE.residual / SSE.total
  
  
}


kable(R2)

hist(R2$Efficacy_R2)

```



## Checking the reward learning model

### N trials back by reward

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

model = readRDS("model.reward.by.previous.efficacy_5.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# IsRewardedRew_min_NRew 
t = hypothesis(model,"IsRewardedRew_min_NRew <0")
estimates[2] = t$hypothesis$Post.Prob

# IsRewarded_T12M1 
t = hypothesis(model,"IsRewarded_T12M1 <0")
estimates[3] = t$hypothesis$Post.Prob

# IsRewarded_T22M1 
t = hypothesis(model,"IsRewarded_T22M1 <0")
estimates[4] = t$hypothesis$Post.Prob

# IsRewarded_T32M1 
t = hypothesis(model,"IsRewarded_T32M1 <0")
estimates[5] = t$hypothesis$Post.Prob

# IsRewarded_T42M1 
t = hypothesis(model,"IsRewarded_T42M1 <0")
estimates[6] = t$hypothesis$Post.Prob

# EffLvlNEff_min_Eff 
t = hypothesis(model,"EffLvlNEff_min_Eff <0")
estimates[7] = t$hypothesis$Post.Prob

# Efficacy_T12M1 
t = hypothesis(model,"Efficacy_T12M1 <0")
estimates[8] = t$hypothesis$Post.Prob

# IsRewarded_T22M1 
t = hypothesis(model,"IsRewarded_T22M1 <0")
estimates[9] = t$hypothesis$Post.Prob

# Efficacy_T22M1 
t = hypothesis(model,"Efficacy_T22M1 <0")
estimates[10] = t$hypothesis$Post.Prob

# Efficacy_T42M1 
t = hypothesis(model,"Efficacy_T42M1 <0")
estimates[11] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept=0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# IsRewardedRew_min_NRew 
t = hypothesis(model,"IsRewardedRew_min_NRew=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T12M1 
t = hypothesis(model,"IsRewarded_T12M1=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T22M1 
t = hypothesis(model,"IsRewarded_T22M1=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T32M1 
t = hypothesis(model,"IsRewarded_T32M1=0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T42M1 
t = hypothesis(model,"IsRewarded_T42M1=0")
estimates[6] = 1/(t$hypothesis$Evid.Ratio)

# EffLvlNEff_min_Eff 
t = hypothesis(model,"EffLvlNEff_min_Eff=0")
estimates[7] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T12M1 
t = hypothesis(model,"Efficacy_T12M1=0")
estimates[8] = 1/(t$hypothesis$Evid.Ratio)

# IsRewarded_T22M1 
t = hypothesis(model,"Efficacy_T12M1=0")
estimates[9] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T22M1 
t = hypothesis(model,"Efficacy_T32M1=0")
estimates[10] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy_T42M1 
t = hypothesis(model,"Efficacy_T42M1=0")
estimates[11] = 1/(t$hypothesis$Evid.Ratio)


# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```


Plot

```{r,warning=FALSE, message=FALSE}



# Plot

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS1_A1.pdf")

p = stanplot(model, pars = c("^b_IsRewarded",
                                        "^b_IsRewarded_T12M1",
                                        "^b_IsRewarded_T22M1",
                                        "^b_IsRewarded_T32M1",
                                        "^b_IsRewarded_T42M1",
                             "^b_EffLvlNEff_min_Eff",
                                        "^b_Efficacy_T12M1",
                                        "^b_Efficacy_T22M1",
                                        "^b_Efficacy_T32M1",
                                        "^b_Efficacy_T42M1")) 
  
p = p +  scale_y_discrete(labels= c(
            "t-4 Efficacy",
          "t-3 Efficacy",
          "t-2 Efficacy",
          "t-1 Efficacy",
          "t Efficacy",
          "t-4 Reward",
          "t-3 Reward",
          "t-2 Reward",
          "t-1 Reward",
          "t Reward"),limits = rev(levels(p[["data"]][["parameter"]]))) +
  
  geom_vline(xintercept=0, linetype="dashed", color = "black") +
  
  labs(x = "Regression estimate", y = "Feedback\n") + 
  scale_x_continuous(limits = c(-0.05,0.23),breaks=seq(-0.05, 0.25, by = 0.05)) + 

  
  # ggtitle("Predicting reported efficacy\n") + 

  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18,family = "", face = "plain",hjust=0),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))
  
f.2.a=p
p

dev.off()

p


pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure2A_RigthNew.pdf")

p = stanplot(model, pars = c("^b_IsRewarded",
                                        "^b_IsRewarded_T12M1",
                                        "^b_IsRewarded_T22M1",
                                        "^b_IsRewarded_T32M1",
                                        "^b_IsRewarded_T42M1",
                             "^b_EffLvlNEff_min_Eff",
                                        "^b_Efficacy_T12M1",
                                        "^b_Efficacy_T22M1",
                                        "^b_Efficacy_T32M1",
                                        "^b_Efficacy_T42M1")) + coord_flip()
  
p = p +  scale_y_discrete(labels= c(
            "t-4",
          "t-3",
          "t-2",
          "t-1",
          "t",
          "t-4",
          "t-3",
          "t-2",
          "t-1",
          "t"),limits = rev(levels(p[["data"]][["parameter"]]))) +
  
  geom_vline(xintercept=0, linetype="dashed", color = "black") +
  
  labs(x = "Regression estimate", y = "Feedback\n") + 
  scale_x_continuous(limits = c(-0.05,0.23),breaks=seq(-0.05, 0.25, by = 0.05)) + 

  
  # ggtitle("Predicting reported efficacy\n") + 

  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18,family = "", face = "plain",hjust=0),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))
  
f.2.a=p
p

dev.off()

p




```


### Predicting the subjective estimates

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

model = readRDS("model.reward.subest_by_modelbased.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```



Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# Efficacy
t = hypothesis(model,"mbased_reward <0")
estimates[2] = t$hypothesis$Post.Prob

# Efficacy_T12M1 
t = hypothesis(model,"mbased_efficacy <0")
estimates[3] = t$hypothesis$Post.Prob



# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept=0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# Reward
t = hypothesis(model,"mbased_reward=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# Efficacy 
t = hypothesis(model,"mbased_efficacy=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")




```

Bayes R2
```{r, warning=FALSE, message=FALSE}
bayes_R2(model)
```

Plot

```{r,warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "mbased_efficacy",plot=FALSE)
# pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_C.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        xlab("Model-based efficacy estimate")+
        ylab(expression(paste("Subjective efficacy estimate")))+
  scale_x_continuous(labels = scaleFUN)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p

p = marginal_effects(model, effects = "mbased_reward",plot=FALSE)
# pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_C.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        xlab("Model-based reward estimate")+
        ylab(expression(paste("Subjective reward estimate")))+
  scale_x_continuous(labels = scaleFUN)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p


```



### Learning rates

```{r,warning=FALSE, message=FALSE}

#### Import the learning rates for reward ###### 

learning_rates_reward = read.csv(file = here("Analyses/Experiment1/RL_fitting/Hierarchical/4_Intercept_Pos_and_neg_learning_rate/results","learning_rates_reward.csv"),header=F,na.strings="NaN")


# add the subject names
learning_rates_reward$SubID = unique(data.raw$SubID)

# rename the variable names
colnames(learning_rates_reward)[1] <- "positive_learning_rate"
colnames(learning_rates_reward)[2] <- "negative_learning_rate"
colnames(learning_rates_reward)[3] <- "initial_bias"
colnames(learning_rates_reward)[4] <- "subject"


# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
# names(myColors) = levels(data$Congruency)
# colScale = scale_colour_manual(name = "Congruency",values = myColors)
barfill <- "#4271AE"
barlines <- "#1F3552"

# Positive efficacy learning rates 
p =ggplot(learning_rates_reward, aes(positive_learning_rate)) + 
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) + 
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) + 
        geom_vline(xintercept=mean(learning_rates_reward$positive_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_reward$positive_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_reward$positive_learning_rate),digits = 2))),size=5) + 


        labs(x = "Positive learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


# Negative efficacy learning rates 
p =ggplot(learning_rates_reward, aes(negative_learning_rate)) + 
        geom_histogram(colour = barlines, fill = barfill,binwidth = 0.01)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,8),breaks=seq(0, 10, by = 1)) + 
        scale_x_continuous(limits = c(-0.01,0.5),breaks=seq(0, 0.6, by = 0.1)) + 
        geom_vline(xintercept=mean(learning_rates_reward$negative_learning_rate), linetype="dashed", color = "black") +
        geom_text(x=mean(learning_rates_reward$negative_learning_rate)+0.07, y=7, label=print(paste0("Mean =  ", round(mean(learning_rates_reward$negative_learning_rate),digits = 2))),size=5) + 


        labs(x = "Negative learning rate", y = "Count\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

f.2.d = p
p

# Positive vs. negative LRs 

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS1_C.pdf")

p =ggplot(learning_rates_reward, aes(positive_learning_rate,negative_learning_rate)) + 
        geom_point(colour = barlines, fill = barfill,size = 4)+ #colour = barlines, fill = barfill
        # ggtitle("Learning rates for the efficacy estimate\n") +
        theme_bw() +
        scale_y_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) + 
        scale_x_continuous(limits = c(0,1),breaks=seq(0, 1, by = 0.2)) + 
        geom_abline(intercept = 0,slope=1, linetype="dashed", color = "black") +
        ylim(0,0.4)+
  xlim(0,0.4)+

        labs(x = "\nPositive learning rate", y = "Negative learning rate\n")+
  theme(axis.line = element_line(size=1, colour = "black"),
            panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
            panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p

dev.off()

p



```

### Statistical comparison of the learning rates
#### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.ttest.learning_rates_reward.rds")

```



#### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "HDI (95%)"),align = "lrrrr")
```

#### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "Learning_rate_type",plot=FALSE)

p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("Learning rate type")))+
        ylab(paste("Learning rate"))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p


```


#### Inference about the model


Check the LR difference

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_Learning_rate_type2M1"]]

hypothesis(model,"Learning_rate_type2M1  >0")


plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

BF for the LR difference

```{r, warning=FALSE, message=FALSE}


hypothesis(model,"Learning_rate_type2M1  =0")


```





### Average R2 for the learning model
```{r,warning=FALSE, message=FALSE}

###### Calculate the average R2 #####

### Reward rate
data.reward = subset(data,is.na(RewRateProbeResp)!=1)

# Calculate the mean efficacy probe response per subject
MeanRewProbe=mean(data.reward$RewRateProbeResp,na.rm=TRUE)

# Calculate the SSE total
SSE.total = sum((data.reward$RewRateProbeResp - MeanRewProbe)^2)

# Calculate the SSE residual
SSE.residual = sum((data.reward$RewRateProbeResp - data.reward$mbased_reward)^2)

# Calculate the R2
R2.reward = 1 - SSE.residual/SSE.total

```


R2 for reward is  `r R2.reward`


### Per subject R2 for the learning model

```{r,warning=FALSE, message=FALSE}

###### Calculate the R2 per subject #####

# Initialize the dataframe
R2 = zeros(length(unique(data$SubID)),2)
colnames(R2) = c("SubID","Reward_R2")
R2 = as.data.frame(R2)


# For each subject
for (s in 1:length(unique(data$SubID))) {
  # Save the subject number
  R2$SubID[s] = unique(data.raw$SubID)[s]
  
  
  ### Reward rate
  data.reward = subset(data, is.na(RewRateProbeResp) != 1 & data$SubID == unique(data.raw$SubID)[s])
  
  # Calculate the mean efficacy probe response per subject
  MeanRewProbe=mean(data.reward$RewRateProbeResp,na.rm=TRUE)

  # Calculate the SSE total
  SSE.total = sum((data.reward$RewRateProbeResp - MeanRewProbe)^2)
  
  # Calculate the SSE residual
  SSE.residual = sum((data.reward$RewRateProbeResp - data.reward$mbased_reward) ^ 2)
  
  # Calculate the R2
  R2$Reward_R2[s] = 1 - SSE.residual / SSE.total
  
}


kable(R2)

hist(R2$Reward_R2)
```




### Average R2 for the 5-running average
```{r,warning=FALSE, message=FALSE}

###### Calculate the average R2 #####

### Reward rate
data.reward = subset(data,is.na(RewRateProbeResp)!=1)

# Calculate the mean efficacy probe response per subject
data.reward = ddply(data.reward,.(SubID),transform, MeanRewProbe=mean(RewRateProbeResp,na.rm=TRUE))

# Calculate the SSE total
SSE.total = sum((data.reward$RewRateProbeResp - data.reward$MeanRewProbe)^2)

# Calculate the SSE residual
SSE.residual = sum((data.reward$RewRateProbeResp - data.reward$runAvgRewRate)^2)

# Calculate the R2
R2.reward = 1 - SSE.residual/SSE.total

```


R2 for reward is  `r R2.reward`

### Per subject R2 for the 5-running average

```{r,warning=FALSE, message=FALSE}

###### Calculate the R2 per subject #####

# Initialize the dataframe
R2 = zeros(length(unique(data$SubID)),2)
colnames(R2) = c("SubID","Reward_R2")
R2 = as.data.frame(R2)


# For each subject
for (s in 1:length(unique(data$SubID))) {
  # Save the subject number
  R2$SubID[s] = unique(data.raw$SubID)[s]
  
  ### Reward rate
  data.reward = subset(data, is.na(RewRateProbeResp) != 1 & data$SubID == unique(data.raw$SubID)[s])
  
  # Calculate the mean efficacy probe response per subject
  MeanRewProbe=mean(data.reward$RewRateProbeResp,na.rm=TRUE)

  # Calculate the SSE total
  SSE.total = sum((data.reward$RewRateProbeResp - MeanRewProbe)^2)
  
  # Calculate the SSE residual
  SSE.residual = sum((data.reward$RewRateProbeResp - data.reward$runAvgRewRate) ^ 2)
  
  # Calculate the R2
  R2$Reward_R2[s] = 1 - SSE.residual / SSE.total
  
}


kable(R2)

hist(R2$Reward_R2)
```



## ERP plots

### Midline

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPMidline.png')
```

### Cue

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPCue.png')
```

### Target

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPTargetN2.png')
```

### Response

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPResponseERN.png')
```

### Efficacy feedback

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_P3a_FCz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_EffSplit_P3a_FCz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_P3b_Pz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_EffSplit_P3b_Pz.png')



knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_EffSplit_P3b_Pz_when_eff_first.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_EffSplit_P3b_Pz_when_rew_first.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPEfficacyFB_EffSplit_P3b_Pz_when_noreward_first.png')
```

### Reward feedback

```{r,warning=T, message=T}
knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPRewardFB_P3a_FCz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPRewardFB_EffSplit_P3a_FCz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPRewardFB_P3b_Pz.png')

knitr::include_graphics('C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Data/Experiment1/EEG/ERP_plots/ERPRewardFB_EffSplit_P3b_Pz.png')
```

## Re-scale data 
```{r,warning=FALSE, message=FALSE}
# Center the continuous variables 
data$Trial = scale(data$Trial/288, scale= FALSE, center = TRUE)
data$ReportedEfficacyLin = scale(data$ReportedEfficacyLin, scale= FALSE, center = TRUE)
data$ReportedRewRateLin = scale(data$ReportedRewRateLin, scale= FALSE, center = TRUE)

#data = ddply(data,.(SubID),plyr::mutate,runAvgRewRate = scale(runAvgRewRate, scale= FALSE, center = TRUE)) # mean RT per condition

data$runAvgRewRate = scale(data$runAvgRewRate, scale= FALSE, center = TRUE)
data$BIC_efficacy = scale(data$BIC_efficacy, scale= TRUE, center = TRUE)
data$BIC_reward = scale(data$BIC_reward, scale= TRUE, center = TRUE)

data$runAvgEfficacy = scale(data$runAvgEfficacy, scale= FALSE, center = TRUE)
data$mbased_efficacy = scale(data$mbased_efficacy, scale= FALSE, center = TRUE)
data$mbased_reward = scale(data$mbased_reward, scale= FALSE, center = TRUE)
data$mbased_efficacy_prev = scale(data$mbased_efficacy_prev, scale= FALSE, center = TRUE)
data$mbased_reward_prev = scale(data$mbased_reward_prev, scale= FALSE, center = TRUE)

data$mbased_efficacy_update = scale(data$mbased_efficacy_update, scale= FALSE, center = TRUE)
data$mbased_efficacy_absolute_update = scale(data$mbased_efficacy_absolute_update, scale= FALSE, center = TRUE)
data$mbased_reward_update = scale(data$mbased_reward_prev, scale= FALSE, center = TRUE)
data$mbased_reward_absolute_update = scale(data$mbased_reward_absolute_update, scale= FALSE, center = TRUE)

data$Accuracy_smooth = scale(data$Accuracy_smooth, scale= FALSE, center = TRUE)
data$RT_smooth = scale(data$RT_smooth/1000, scale= FALSE, center = TRUE)
data$Spearman_r_eff = scale(data$Spearman_r_eff, scale= FALSE, center = TRUE)
data$Spearman_r_rew_rate = scale(data$Spearman_r_rew_rate, scale= FALSE, center = TRUE)
#data$EffLvl = ifelse(data$EffLvl=="Efficacy",0.5,-0.5)
#data$IsRewarded = ifelse(data$IsRewarded=="Reward",0.5,-0.5)
data$feedbackOrder = ifelse(data$feedbackOrder==1,"Efficacy_First","Efficacy_Second") # 1 is first efficacy
data$feedbackOrder = as.factor(data$feedbackOrder)
contrasts(data$feedbackOrder) <- contr.sdif(2)
data$EffLvl = as.factor(data$EffLvl)
data$IsRewarded = as.factor(data$IsRewarded)
contrasts(data$EffLvl) <- contr.sdif(2)
colnames(attr(data$EffLvl, "contrasts")) =  c("NEff_min_Eff") # Change the name of the contrasts
contrasts(data$IsRewarded) <- contr.sdif(2)
colnames(attr(data$IsRewarded, "contrasts")) =  c("Rew_min_NRew") # Change the name of the contrasts
data$Congruency = ordered(data$Congruency, levels = c("Congruent", "Neutral", "Incongruent"))  # first contrast is facilitaion and the second one is interference
contrasts(data$Congruency) <- contr.sdif(3)
colnames(attr(data$Congruency, "contrasts")) =  c("Facilitation", "Interference") # Change the name of the contrasts
data$Accuracy = data$Acc
data$Accuracy = ifelse(data$Accuracy==1,"Correct","Incorrect") 
data$Accuracy = as.factor(data$Accuracy)
contrasts(data$Accuracy) <- contr.sdif(2)
colnames(attr(data$Accuracy, "contrasts")) =  c("Inc_min_Corr") # Change the name of the contrasts
data$Rew_eff_fb = as.factor(data$Rew_eff_fb)
data$Rew_eff_fb = ordered(data$Rew_eff_fb, levels = c("NoReward", "Reward", "RewardUnknown"))
contrasts(data$Rew_eff_fb) <- contr.sdif(3)
colnames(attr(data$Rew_eff_fb, "contrasts")) =  c("Rew_min_NRew","RewUnk_min_Rew") # Change the name of the contrasts
data$Eff_rew_fb = as.factor(data$Eff_rew_fb)
data$Eff_rew_fb = ordered(data$Eff_rew_fb, levels = c("NoEfficacy", "Efficacy", "EfficacyUnknown"))
contrasts(data$Eff_rew_fb) <- contr.sdif(3)
colnames(attr(data$Eff_rew_fb, "contrasts")) =  c("Eff_min_NEff","EffUnk_min_Eff") # Change the name of the contrasts
data$LR = scale(data$LR, scale= FALSE, center = TRUE)
data$LR_reward_positive = scale(data$LR_reward_positive, scale= FALSE, center = TRUE)
data$LR_reward_negative = scale(data$LR_reward_negative, scale= FALSE, center = TRUE)
data$LR_efficacy_positive = scale(data$LR_efficacy_positive, scale= FALSE, center = TRUE)
data$LR_efficacy_negative = scale(data$LR_efficacy_negative, scale= FALSE, center = TRUE)
# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
names(myColors) = levels(data$Congruency)
colScale = scale_colour_manual(name = "Congruency",values = myColors)

# x = c(1:10)
# x_centered = scale(x,scale = F,center = T)
# y = x_centered + attr(x_centered,'scaled:center')
# y==x

# Save data for hddm
# data_for_hddm = data
# colnames(data_for_hddm)[which(names(data_for_hddm) == "RT")] = "rt"
# colnames(data_for_hddm)[which(names(data_for_hddm) == "SubID")] = "subj_idx"
# colnames(data_for_hddm)[which(names(data_for_hddm) == "Acc")] = "response"
# 
# data_for_hddm = data_for_hddm %>% ungroup()%>% dplyr::select(subj_idx,response, rt, runAvgEfficacy, runAvgRewRate, Congruency)
# 
# data_for_hddm = subset(data_for_hddm, (!is.na(data_for_hddm$rt)))

# data_for_hddm$Congruency[data_for_hddm$Congruency=="Congruent"]="2Congruent"
# data_for_hddm$Congruency[data_for_hddm$Congruency=="Incongruent"]="1Incongruent"
# data_for_hddm$Congruency[data_for_hddm$Congruency=="Neutral"]="2Neutral"

# 
# data_for_hddm$Congruency = as.character(data_for_hddm$Congruency)
# 
# 
# 
# write.csv(data_for_hddm,"data_for_hddm.csv")

# Delete subjects with low learning rates

# subjects with low learning rates
# subs_low_lr = c(1041,1043,1051, 1056,1054,1059,1061,1068,1070,1063)
# 
# data = data[!data$SubID %in% subs_low_lr,]



```


## Checking reward probability


### Reward probability by efficacy level

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))
model = readRDS("model.model.reward_probability_EffLvl1.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
# pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# Temp fix
x = x[-12,] 

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# Efficacy_T02M1 
t = hypothesis(model,"EffLvlNEff_min_Eff  <0")
estimates[2] = t$hypothesis$Post.Prob



# add the probabilities to the table
x$Posterior = estimates



x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability"),align = "lrrrr")

```

Plot

```{r,warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "EffLvl",plot=FALSE)

p = plot(p,plot=FALSE)[[1]]+
        # labs(x = "Congruency", y = "Accuracy")+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p



```




### Reward probability by efficacy estimate

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))
model = readRDS("model.model.reward_probability_Effmbased1.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
# pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# Temp fix
x = x[-12,] 

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# Efficacy_T02M1 
t = hypothesis(model,"mbased_efficacy_feedback_locked   <0")
estimates[2] = t$hypothesis$Post.Prob



# add the probabilities to the table
x$Posterior = estimates



x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability"),align = "lrrrr")

```

Plot

```{r,warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "mbased_efficacy_feedback_locked",plot=FALSE) 

p = plot(p,plot=FALSE)[[1]]+
        # labs(x = "Congruency", y = "Accuracy")+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p


```





### Reward estimate by efficacy estimate

```{r,warning=FALSE, message=FALSE}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))
model = readRDS("model.model.Rewmbased_Effmbased1.rds")
```

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```

Posterior predictive check

```{r, warning=FALSE, message=FALSE}
# Plot chains
# pp_check(model)
```

Summary of the model 

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# Temp fix
x = x[-12,] 

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# Efficacy_T02M1 
t = hypothesis(model,"mbased_efficacy  <0")
estimates[2] = t$hypothesis$Post.Prob



# add the probabilities to the table
x$Posterior = estimates



x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability"),align = "lrrrr")

```

Plot

```{r,warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "mbased_efficacy",plot=FALSE) 

p = plot(p,plot=FALSE)[[1]]+
        # labs(x = "Congruency", y = "Accuracy")+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p


```






## Correct RTs 

### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.congruency_plus_efficacy.RT.rds")
# loo = readRDS("compare.RT.loo")
# bR2.1 = readRDS("bR2.model.congruency.RT")
# bR2.2 = readRDS("bR2.model.congruency_plus_efficacy.RT")
# bR2.3 = readRDS("bR2.model.congruency_times_efficacy.RT")
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])

```



### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model

```{r, warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "Congruency",plot=FALSE) 
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS4_A.pdf")
p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Congruency", y = "Reaction times (ms)")+
        # geom_errorbar(size=1) +
        # geom_point(size=2) +
        ylim(600,725)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p

p = marginal_effects(model, effects = "mbased_reward_prev")

p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Reward rate (model-based estimate)", y = "Reaction times (ms)")+
            # scale_y_continuous(limits = c(600,670),breaks=seq(600, 680, by = 10)) + 
        # scale_x_continuous(limits = c(-0.6,0.5),breaks=seq(-0.5, 0.5, by = 0.1)) + 
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p


p = marginal_effects(model, effects = "mbased_efficacy_prev")
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_A.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Efficacy estimate", y = "Reaction times (ms)")+
        scale_x_continuous(labels = scaleFUN)    +    
  # scale_y_continuous(limits = c(600,670),breaks=seq(600, 680, by = 10)) + 
        # scale_x_continuous(limits = c(-0.6,0.5),breaks=seq(-0.5, 0.5, by = 0.1)) + 
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))

p
dev.off()
p




# 
# p = marginal_effects(model, effects = "mbased_efficacy_prev:Congruency",plot=FALSE)
# 
# p = plot(p,plot=FALSE)[[1]]+
#         xlab("Efficacy (model-based estimate)")+
#         ylab("Reaction times (ms)")+
#         theme(axis.line = element_line(size=1, colour = "black"),
#               panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(), 
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# 
# p


```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL



# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# CongruencyFacilitation
t = hypothesis(model,"CongruencyFacilitation<0")
estimates[2] = t$hypothesis$Post.Prob

# CongruencyInterference
t = hypothesis(model,"CongruencyInterference<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev<0")
estimates[4] = t$hypothesis$Post.Prob

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev<0")
estimates[5] = t$hypothesis$Post.Prob

# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept = 624")
estimates[1] = t$hypothesis$Evid.Ratio

# CongruencyFacilitation
t = hypothesis(model,"CongruencyFacilitation=15.54")
estimates[2] = t$hypothesis$Evid.Ratio

# CongruencyInterference
t = hypothesis(model,"CongruencyInterference=61.12")
estimates[3] = t$hypothesis$Evid.Ratio

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev=-10.26")
estimates[4] = t$hypothesis$Evid.Ratio

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev=0")
estimates[5] = t$hypothesis$Evid.Ratio

# add the probabilities to the table
x$BF = estimates

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF01"),align = "lrrrrr")
```


### Inference about the model


Check the interference effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
interference = post[["b_CongruencyInterference"]]

plotPost(interference, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

Check the facilitation effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
facilitation = post[["b_CongruencyFacilitation"]]

plotPost(facilitation, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

Check the reward effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```


Check the efficacy effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_efficacy_prev=0")
p=hypothesis(model,"mbased_efficacy_prev=-10.26")
p
plot(p)
```

Calculate the priors for experiment 2

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")

# Intercept
intercept = post[["b_Intercept"]]

plotPost(intercept, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Intercept Mean = ",mean(intercept)))
print(paste0("Intercept SD = ",sd(intercept)))

# Congruency
interference = post[["b_CongruencyInterference"]]
facilitation = post[["b_CongruencyFacilitation"]]

congruency = interference + facilitation

plotPost(congruency, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Congruency Mean = ",mean(congruency)))
print(paste0("Congruency SD = ",sd(congruency)))

# Efficacy
efficacy = post[["b_mbased_efficacy_prev"]]

plotPost(efficacy, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Efficacy Mean = ",mean(efficacy)))
print(paste0("Efficacy SD = ",sd(efficacy)))

# Reward
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Reward Mean = ",mean(reward)))
print(paste0("Reward SD = ",sd(reward)))

```

## Accuracy

### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.congruency_plus_efficacy.Acc.rds")
# loo = readRDS("compare.Acc.loo")
# bR2.1 = readRDS("bR2.model.congruency.Acc")
# bR2.2 = readRDS("bR2.model.congruency_plus_efficacy.Acc")
# bR2.3 = readRDS("bR2.model.congruency_times_efficacy.Acc")
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])
```



### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model

```{r, warning=FALSE, message=FALSE}

p = marginal_effects(model, effects = "Congruency",plot=FALSE) 
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS4_B.pdf")

p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Congruency", y = "Accuracy")+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        ylim (0.7,1)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p

p = marginal_effects(model, effects = "mbased_reward_prev")

p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Reward rate (model-based estimate)", y = "Accuracy")+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p
f.3.e = p

p = marginal_effects(model, effects = "mbased_efficacy_prev")
scaleFUN <- function(x) sprintf("%.1f", x)
p = plot(p,plot=FALSE)[[1]]+
        labs(x = "Efficacy (model-based estimate)", y = "Accuracy")+
        scale_x_continuous(labels = scaleFUN) + 
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p
f.3.f = p





# p = marginal_effects(model, effects = "mbased_efficacy_prev:Congruency",plot=FALSE)
# 
# p = plot(p,plot=FALSE)[[1]]+
#         xlab("Efficacy (model-based estimate)")+
#         ylab("Accuracy")+
#         theme(axis.line = element_line(size=1, colour = "black"),
#               panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(), 
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# 
# p




```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# CongruencyFacilitation
t = hypothesis(model,"CongruencyFacilitation<0")
estimates[2] = t$hypothesis$Post.Prob

# CongruencyInterference
t = hypothesis(model,"CongruencyInterference<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev<0")
estimates[4] = t$hypothesis$Post.Prob

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev<0")
estimates[5] = t$hypothesis$Post.Prob

# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept = 2.11")
estimates[1] = t$hypothesis$Evid.Ratio

# CongruencyFacilitation
t = hypothesis(model,"CongruencyFacilitation=-0.45")
estimates[2] = t$hypothesis$Evid.Ratio

# CongruencyInterference
t = hypothesis(model,"CongruencyInterference=-0.53")
estimates[3] = t$hypothesis$Evid.Ratio

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev=0.09")
estimates[4] = t$hypothesis$Evid.Ratio

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev=0")
estimates[5] = t$hypothesis$Evid.Ratio

# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF01"),align = "lrrrrr")
```


### Inference about the model


Check the interference effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
interference = post[["b_CongruencyInterference"]]

plotPost(interference, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

Check the facilitation effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
facilitation = post[["b_CongruencyFacilitation"]]

plotPost(facilitation, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```

Check the reward effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```


Check the efficacy effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

p=hypothesis(model, "mbased_efficacy_prev=0.09")
p
plot(p)
```

Calculate the priors for experiment 2

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")

# Intercept
intercept = post[["b_Intercept"]]

plotPost(intercept, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Intercept Mean = ",mean(intercept)))
print(paste0("Intercept SD = ",sd(intercept)))

# Congruency
interference = post[["b_CongruencyInterference"]]
facilitation = post[["b_CongruencyFacilitation"]]

congruency = interference + facilitation

plotPost(congruency, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Congruency Mean = ",mean(congruency)))
print(paste0("Congruency SD = ",sd(congruency)))

# Efficacy
efficacy = post[["b_mbased_efficacy_prev"]]

plotPost(efficacy, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Efficacy Mean = ",mean(efficacy)))
print(paste0("Efficacy SD = ",sd(efficacy)))

# Reward
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

print(paste0("Reward Mean = ",mean(reward)))
print(paste0("Reward SD = ",sd(reward)))

```

## Late CNV

### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.efficacy.lateCNV.rds")
# loo = readRDS("compare.lateCNV.loo")
# bR2.1 = readRDS("bR2.model.efficacy.lateCNV")
# bR2.2 = readRDS("bR2.model.efficacy_times_reward.lateCNV")
# 
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])
```




### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "mbased_efficacy_prev",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_C.pdf",4,7)

scaleFUN <- function(x) sprintf("%.1f", x)

p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy estimate")+
        ylab(expression(paste("CNV [", mu,"V]")))+
  scale_x_continuous(labels = scaleFUN)+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p




p = marginal_effects(model, effects = "mbased_reward_prev")

p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward rate (model-based estimate)")+
        ylab(expression(paste("Late CNV [", mu,"V]")))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p
f.4.b =p

```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Tail_ESS = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept > 0")
estimates[1] = t$hypothesis$Post.Prob

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev>0")
estimates[2] = t$hypothesis$Post.Prob

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev>0")
estimates[3] = t$hypothesis$Post.Prob

# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept = -0.16")
estimates[1] = t$hypothesis$Evid.Ratio

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev=-0.30")
estimates[2] = t$hypothesis$Evid.Ratio

# mbased_reward_prev
t = hypothesis(model,"mbased_reward_prev=0")
estimates[3] = t$hypothesis$Evid.Ratio

# add the probabilities to the table
x$BF = estimates

x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability", "BF01"),align = "lrrrrr")

```


### Inference about the model


Check the efficacy effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

p=hypothesis(model,"mbased_efficacy_prev=-0.30")
p
plot(p)
```

Check the reward effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)
```









## Late CNV predicting RTs

### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.RT.lateCNV.rds")
# bR2.1 =  readRDS("bR2.model.RT.lateCNV")

```




### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```



### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "CNV10001500",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_D.pdf") 
p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("CNV [", mu,"V]")))+
        ylab(paste("Reaction times (ms)"))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))
p
dev.off()
p

```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# CNV10001500
t = hypothesis(model,"CNV10001500<0")
estimates[2] = t$hypothesis$Post.Prob

# add the probabilities to the table
x$Posterior = estimates

#Add BFs

# Intercept
t = hypothesis(model,"Intercept = 0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# CNV10001500
t = hypothesis(model,"CNV10001500=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# add the probabilities to the table
x$BF = estimates

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,format.args = list(scientific = FALSE),col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```


### Inference about the model


Check the late CNV effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_CNV10001500"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"CNV10001500=0")
```











## Late CNV predicting Accuracy

### Import the model

```{r,warning=T, message=T}
# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

model = readRDS("model.Acc.lateCNV.rds")
# bR2.1 =  readRDS("bR2.model.Acc.lateCNV")

```




### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model

```{r, warning=FALSE, message=FALSE}


p = marginal_effects(model, effects = "CNV10001500",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure4_E.pdf")
p = plot(p,plot=FALSE)[[1]]+
        xlab(expression(paste("CNV [", mu,"V]")))+
        ylab(expression(paste("Accuracy")))+
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p

```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept < 0")
estimates[1] = t$hypothesis$Post.Prob

# CNV10001500
t = hypothesis(model,"CNV10001500<0")
estimates[2] = t$hypothesis$Post.Prob

# add the probabilities to the table
x$Posterior = estimates

#Add BFs

# Intercept
t = hypothesis(model,"Intercept = 0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# CNV10001500
t = hypothesis(model,"CNV10001500=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# add the probabilities to the table
x$BF = estimates

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```


### Inference about the model


Check the late CNV effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_CNV10001500"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"CNV10001500=0")

```



## P3b efficacy - Estimate*feedback

### Import the model

```{r,warning=T, message=T}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

# model = readRDS("model.efficacy.P3b.PE.LR.rds")
model = readRDS("model.efficacy.P3b.efficacy_times_feedback.rds")
# model = readRDS("model.efficacy.P3b.efficacy_times_feedback_times_LR_bias.rds")
# model = readRDS("model.efficacy.P3b.efficacy_times_feedback_times_LR.rds")



# 
# loo = readRDS("compare.P3b.efficacy.loo")
# bR2.1 = readRDS("bR2.model.efficacy.P3b.PE")
# bR2.2 = readRDS("bR2.model.efficacy.P3b.PE.LR")
# bR2.3 = readRDS("bR2.model.efficacy.P3b.PE_times_LR")
# 
# 
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])

```


### Bayesian R squared 


```{r, warning=FALSE, message=FALSE}
# R2 = rbind(bR2.1,bR2.2,bR2.3)
# row.names(R2) =  c("Unsigned PE model","Unsigned PE + LR model","Unsigned PE * LR model")
# kable(R2,digits = 4)
```


### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model


```{r, warning=FALSE, message=FALSE}
# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
myColors = brewer.pal(3,"Set2") #colors



p = conditional_effects(model, effects = "mbased_efficacy_prev",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p


p = conditional_effects(model, effects = "mbased_reward_feedback_locked",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

p = conditional_effects(model, effects = "EffLvl",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy feedback")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

# p = conditional_effects(model, effects = "mbased_efficacy_prev:EffLvl",plot=FALSE)
# 
# 
# p = plot(p,plot=FALSE)[[1]]+
#         xlab("Efficacy estimate")+
#         ylab(expression(paste("P3b [", mu,"V]")))+
#         #   geom_errorbar(size=1) +
#         # geom_point(size=2) +
#         theme(axis.line = element_line(size=1, colour = "black"),
#               panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
#               panel.border = element_blank(),
#               panel.background = element_blank(),
#               plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
#               text=element_text(colour="black", size = 14),
#               axis.text.x=element_text(colour="black", size = 14),
#               axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
#               axis.title=element_text(size=18,colour = "black",vjust = 1))
# 
# p

pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure3_B.pdf")
p = conditional_effects(model, effects = "mbased_efficacy_prev:EffLvl")

# # Uncenter
# p[["mbased_efficacy_prev:EffLvl"]][["effect1__"]] = p[["mbased_efficacy_prev:EffLvl"]][["effect1__"]] + attr(p[["mbased_efficacy_prev:EffLvl"]][["effect1__"]],'scaled:center')

# Change the factor names for plotting
attr(p$`mbased_efficacy_prev:EffLvl`,"effects") = c("Efficacy estimate (model-based)","Efficacy level")
p$`mbased_efficacy_prev:EffLvl`$effect2__=revalue(p$`mbased_efficacy_prev:EffLvl`$effect2__, c("NoEfficacy"="Random", "Efficacy"="Performance-Based"))
p$`mbased_efficacy_prev:EffLvl`$effect2__ = factor(p$`mbased_efficacy_prev:EffLvl`$effect2__, levels=rev(levels(p$`mbased_efficacy_prev:EffLvl`$effect2__)))

p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
            # scale_color_brewer(palette="Set3")+
    scale_color_discrete() + 
  scale_fill_discrete()+
   xlim(-0.5, 0.49)+

        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""),
              legend.position = c(0.8, 0.9))

p
dev.off()

p



```


### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add two more rows
x[6:7,]=zeros(4)

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Posterior probabilities

# Intercept
t = hypothesis(model,"Intercept <0")
estimates[1] = t$hypothesis$Post.Prob

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev<0")
estimates[2] = t$hypothesis$Post.Prob

# EffLvlNEff_min_Eff
t = hypothesis(model,"EffLvlNEff_min_Eff<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_reward_feedback_locked<0")
estimates[4] = t$hypothesis$Post.Prob

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev:EffLvlNEff_min_Eff  < 0")
estimates[5] = t$hypothesis$Post.Prob

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev + 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  <0")
estimates[6] = t$hypothesis$Post.Prob

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev - 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  <0")
estimates[7] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates

# Bayes factors

# Intercept
t = hypothesis(model,"Intercept =0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_prev
t = hypothesis(model,"mbased_efficacy_prev=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# EffLvlNEff_min_Eff
t = hypothesis(model,"EffLvlNEff_min_Eff=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_reward_feedback_locked=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev:EffLvlNEff_min_Eff  = 0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev + 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  =0")
estimates[6] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_prev:EffLvlNEff_min_Eff
t = hypothesis(model,"mbased_efficacy_prev - 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  =0")
estimates[7] = 1/(t$hypothesis$Evid.Ratio)


# add the BFs to the table
x$BF = estimates

# Add the efficacy slope to the table
#initialize the vector
efficacy = NA
t=hypothesis(model,"mbased_efficacy_prev + 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  <0")
efficacy[1] = "Performance-Based feedback"
efficacy[2] = t$hypothesis$Estimate
efficacy[3] = t$hypothesis$Est.Error
efficacy[4] = paste(round(t$hypothesis$CI.Lower,2),", ",round(t$hypothesis$CI.Upper,2))

# add the efficacy slope to the table
x[6,1:4] = efficacy

# Add the no efficacy slope to the table
#initialize the vector
efficacy = NA
t=hypothesis(model,"mbased_efficacy_prev - 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  <0")
efficacy[1] = "Random feedback"
efficacy[2] = t$hypothesis$Estimate
efficacy[3] = t$hypothesis$Est.Error
efficacy[4] = paste(round(t$hypothesis$CI.Lower,2),", ",round(t$hypothesis$CI.Upper,2))

# add the efficacy slope to the table
x[7,1:4] = efficacy

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrrrr")

```


### Inference about the model


Check the reward estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_feedback_locked"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_reward_feedback_locked >0")
```

Check the efficacy estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_efficacy_prev >0")
```

Check the efficacy feedback effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_EffLvlNEff_min_Eff"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"EffLvlNEff_min_Eff  >0")

hypothesis(model,"EffLvlNEff_min_Eff  =0")
```

Check the efficacy estimate X efficacy feedback effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev:EffLvlNEff_min_Eff"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#interaction
hypothesis(model,"mbased_efficacy_prev:EffLvlNEff_min_Eff  >0")

p=hypothesis(model,"mbased_efficacy_prev:EffLvlNEff_min_Eff  =0")
p
plot(p)


```

Check the slope for no efficacy feedback

```{r, warning=FALSE, message=FALSE}

post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]] - 0.5*post[["b_mbased_efficacy_prev:EffLvlNEff_min_Eff"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#slope for efficacy
hypothesis(model,"mbased_efficacy_prev - 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  >0")

p=hypothesis(model,"mbased_efficacy_prev - 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  =0")
p
plot(p)
```


Check the slope for  efficacy feedback

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_prev"]] + 0.5*post[["b_mbased_efficacy_prev:EffLvlNEff_min_Eff"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#slope for  efficacy
hypothesis(model,"mbased_efficacy_prev + 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  >0")

p=hypothesis(model,"mbased_efficacy_prev + 0.5*mbased_efficacy_prev:EffLvlNEff_min_Eff  =0")
p
plot(p)

```





## P3b efficacy - PE*LR

### Import the model

```{r,warning=T, message=T}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

# model = readRDS("model.efficacy.P3b.PE.LR.rds")
model = readRDS("model.efficacy.P3b.PE_times_LR.rds")
# model = readRDS("model.efficacy.P3b.efficacy_times_feedback_times_LR_bias.rds")
# model = readRDS("model.efficacy.P3b.efficacy_times_feedback_times_LR.rds")




# loo = readRDS("compare.P3b.efficacy.loo")
# bR2.1 = readRDS("bR2.model.efficacy.P3b.PE")
# bR2.2 = readRDS("bR2.model.efficacy.P3b.PE.LR")
# bR2.3 = readRDS("bR2.model.efficacy.P3b.PE_times_LR")
# 
# 
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])

```


### Bayesian R squared 


```{r, warning=FALSE, message=FALSE}
# R2 = rbind(bR2.1,bR2.2,bR2.3)
# row.names(R2) =  c("Unsigned PE model","Unsigned PE + LR model","Unsigned PE * LR model")
# kable(R2,digits = 4)
```


### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model


```{r, warning=FALSE, message=FALSE}
# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
myColors = brewer.pal(3,"Set2") #colors


pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure3_C1.pdf")
p = conditional_effects(model, effects = "unsigned_PE_efficacy",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Prediction error")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p
# f.4.e =p

p = conditional_effects(model, effects = "mbased_reward_feedback_locked",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward rate estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

p = conditional_effects(model, effects = "LR_efficacy_raw_zscored",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/Figure3_C2.pdf")


p = plot(p,plot=FALSE)[[1]]+
        xlab("Learning rate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))

p
dev.off()
p

p = conditional_effects(model, effects = "unsigned_PE_efficacy:LR_efficacy_raw_zscored",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Prediction error")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p



# extract the per-subject effects

per_subject_P3a  = data.frame(matrix(ncol = 2, nrow = 40))
colnames(per_subject_P3a) = c("Prediction error","Learning rate")

x=as.data.frame(coef(model, pars = "unsigned_PE_efficacy"))

per_subject_P3a$`Prediction error` = x$SubID.Estimate.unsigned_PE_efficacy

x=as.data.frame(coef(model, pars = "LR_efficacy_raw_zscored"))

per_subject_P3a$`Learning rate` = x$SubID.Estimate.LR_efficacy_raw_zscored

per_subject_P3a=gather(per_subject_P3a, estimate, value, `Prediction error`, `Learning rate`)


p = ggplot(data = per_subject_P3a)+

    geom_point(aes(x=estimate,y=value),shape = 21, position=position_dodge(.9),size=5, color = "black",fill = NA,stroke = 1) +
  geom_hline(yintercept=0, linetype="dashed", color = "black") +
  
  
        xlab("Coeficient")+
        ylab(expression(paste("Regression coefficient value")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p

```




### Table for the results

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept <0")
estimates[1] = t$hypothesis$Post.Prob

# unsigned_PE_efficacy
t = hypothesis(model,"unsigned_PE_efficacy<0")
estimates[2] = t$hypothesis$Post.Prob

# LR_efficacy_raw_zscored
t = hypothesis(model,"LR_efficacy_raw_zscored<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_reward_feedback_locked<0")
estimates[4] = t$hypothesis$Post.Prob

# unsigned_PE_efficacy:LR_efficacy_raw_zscored
t = hypothesis(model,"unsigned_PE_efficacy:LR_efficacy_raw_zscored  < 0")
estimates[5] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates

# Add BFs

# Intercept
t = hypothesis(model,"Intercept =0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# unsigned_PE_efficacy
t = hypothesis(model,"unsigned_PE_efficacy=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# LR_efficacy_raw_zscored
t = hypothesis(model,"LR_efficacy_raw_zscored=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_reward_feedback_locked=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# unsigned_PE_efficacy:LR_efficacy_raw_zscored
t = hypothesis(model,"unsigned_PE_efficacy:LR_efficacy_raw_zscored  = 0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)


# add the probabilities to the table
x$BF = estimates

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```



### Inference about the model


Check the Prediction error effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_unsigned_PE_efficacy"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"unsigned_PE_efficacy>0")
p=hypothesis(model,"unsigned_PE_efficacy=0")
p
plot(p)

hypothesis(model,"unsigned_PE_efficacy=0")



```

Check the learning rate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_LR_efficacy_raw_zscored"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"LR_efficacy_raw_zscored>0")

hypothesis(model,"LR_efficacy_raw_zscored=0")
```

Check the reward estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_feedback_locked"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_reward_feedback_locked>0")
```


Check the Prediction error X learning rate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_unsigned_PE_efficacy:LR_efficacy_raw_zscored"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"unsigned_PE_efficacy:LR_efficacy_raw_zscored>0")

hypothesis(model,"unsigned_PE_efficacy:LR_efficacy_raw_zscored=0")


```









## P3b reward - Estimate*feedback

### Import the model

```{r,warning=T, message=T}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

# model = readRDS("model.efficacy.P3a.PE.rds")
model = readRDS("model.reward.P3b.reward_times_feedback.rds")
# 
# loo = readRDS("compare.P3a.efficacy.loo")
# bR2.1 = readRDS("bR2.model.efficacy.P3a.PE")
# bR2.2 = readRDS("bR2.model.efficacy.P3a.PE.LR")
# bR2.3 = readRDS("bR2.model.efficacy.P3a.PE_times_LR")
# 
# 
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])

```


### Bayesian R squared 


```{r, warning=FALSE, message=FALSE}
# R2 = rbind(bR2.1,bR2.2,bR2.3)
# row.names(R2) =  c("Unsigned PE model","Unsigned PE + LR model","Unsigned PE * LR model")
# kable(R2,digits = 4)
```


### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model


```{r, warning=FALSE, message=FALSE}
# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
myColors = brewer.pal(3,"Set2") #colors



p = conditional_effects(model, effects = "mbased_reward_prev",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward estimate")+
        ylab(expression(paste("P3a [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p


p = conditional_effects(model, effects = "mbased_efficacy_feedback_locked",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy estimate")+
        ylab(expression(paste("P3a [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

p = conditional_effects(model, effects = "IsRewarded",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward feedback")+
        ylab(expression(paste("P3a [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

p = conditional_effects(model, effects = "mbased_reward_prev:IsRewarded",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward estimate")+
        ylab(expression(paste("P3a [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p


pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS3_B.pdf")
p = conditional_effects(model, effects = "mbased_reward_prev:IsRewarded")

# Change the factor names for plotting
attr(p$`mbased_reward_prev:IsRewarded`,"effects") = c("Reward estimate (model-based)","Reward level")
p$`mbased_reward_prev:IsRewarded`$effect2__=revalue(p$`mbased_reward_prev:IsRewarded`$effect2__, c("NoReward"="No Reward", "Reward"="Reward"))
p$`mbased_reward_prev:IsRewarded`$effect2__ = factor(p$`mbased_reward_prev:IsRewarded`$effect2__, levels=rev(levels(p$`mbased_reward_prev:IsRewarded`$effect2__)))

p = plot(p,plot=FALSE)[[1]]+
        xlab("Reward rate estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
            # scale_color_brewer(palette="Set3")+
    scale_color_discrete() + 
  scale_fill_discrete()+
   xlim(-0.5, 0.49)+

        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(), 
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""),
              legend.position = c(0.4, 0.93))

p
dev.off()

p



```




### Table for the results
```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Tail_ESS = NULL
x$Rhat = NULL

# add two more rows
x[6:7,]=zeros(4)

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL


# extract the stats

#initialize the vector
estimates = NA

# Posterior probabilities

# Intercept
t = hypothesis(model,"Intercept <0")
estimates[1] = t$hypothesis$Post.Prob

# mbased_efficacy_prev
t = hypothesis(model,"mbased_reward_prev<0")
estimates[2] = t$hypothesis$Post.Prob

# EffLvlNEff_min_Eff
t = hypothesis(model,"IsRewardedRew_min_NRew<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_efficacy_feedback_locked<0")
estimates[4] = t$hypothesis$Post.Prob

# mbased_reward_prev:IsRewardedRew_min_NRew
t = hypothesis(model,"mbased_reward_prev:IsRewardedRew_min_NRew  < 0")
estimates[5] = t$hypothesis$Post.Prob

# no reward slope
t = hypothesis(model,"mbased_reward_prev + 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  <0")
estimates[6] = t$hypothesis$Post.Prob

# reward slope
t = hypothesis(model,"mbased_reward_prev - 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  <0")
estimates[7] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates

# Bayes factors

# Intercept
t = hypothesis(model,"Intercept =0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_prev
t = hypothesis(model,"mbased_reward_prev=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# EffLvlNEff_min_Eff
t = hypothesis(model,"IsRewardedRew_min_NRew=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# mbased_reward_feedback_locked
t = hypothesis(model,"mbased_efficacy_feedback_locked=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# mbased_reward_prev:IsRewardedRew_min_NRew
t = hypothesis(model,"mbased_reward_prev:IsRewardedRew_min_NRew  = 0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)

# no reward slope
t = hypothesis(model,"mbased_reward_prev + 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  =0")
estimates[6] = 1/(t$hypothesis$Evid.Ratio)

# reward slope
t = hypothesis(model,"mbased_reward_prev - 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  =0")
estimates[7] = 1/(t$hypothesis$Evid.Ratio)


# add the BFs to the table
x$BF = estimates

# Add the reward slope to the table
#initialize the vector
efficacy = NA
t=hypothesis(model,"mbased_reward_prev - 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  <0")
efficacy[1] = "No Reward"
efficacy[2] = t$hypothesis$Estimate
efficacy[3] = t$hypothesis$Est.Error
efficacy[4] = paste(round(t$hypothesis$CI.Lower,2),", ",round(t$hypothesis$CI.Upper,2))

# add the efficacy slope to the table
x[6,1:4] = efficacy

# Add the  reward slope to the table
#initialize the vector
efficacy = NA
t=hypothesis(model,"mbased_reward_prev + 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  <0")
reward[1] = "Reward"
reward[2] = t$hypothesis$Estimate
reward[3] = t$hypothesis$Est.Error
reward[4] = paste(round(t$hypothesis$CI.Lower,2),", ",round(t$hypothesis$CI.Upper,2))

# add the reward slope to the table
x[7,1:4] = reward

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)


# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrrrr")

```


### Inference about the model


Check the efficacy estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_feedback_locked"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_efficacy_feedback_locked >0")
```

Check the reward estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_reward_prev >0")
```

Check the reward feedback effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_IsRewardedRew_min_NRew"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"IsRewardedRew_min_NRew  >0")
```

Check the reward estimate X reward feedback effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev:IsRewardedRew_min_NRew"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#interaction
hypothesis(model,"mbased_reward_prev:IsRewardedRew_min_NRew  >0")

```

Check the slope for no reward feedback

```{r, warning=FALSE, message=FALSE}

post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]] - 0.5*post[["b_mbased_reward_prev:IsRewardedRew_min_NRew"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#slope for efficacy
hypothesis(model,"mbased_reward_prev - 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  >0")

```


Check the slope for reward feedback

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_reward_prev"]] + 0.5*post[["b_mbased_reward_prev:IsRewardedRew_min_NRew"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

#slope for  efficacy
hypothesis(model,"mbased_reward_prev + 0.5*mbased_reward_prev:IsRewardedRew_min_NRew  >0")

```







## P3b reward - PE*LR

### Import the model

```{r,warning=T, message=T}

# Set the working directory in order to load the models
setwd(here("Analyses/Experiment1/Stats/brms/brms_models"))

# Import the models

# model = readRDS("model.efficacy.P3a.PE.rds")
model = readRDS("model.reward.P3b.PE_times_LR.rds")

# loo = readRDS("compare.P3a.efficacy.loo")
# bR2.1 = readRDS("bR2.model.efficacy.P3a.PE")
# bR2.2 = readRDS("bR2.model.efficacy.P3a.PE.LR")
# bR2.3 = readRDS("bR2.model.efficacy.P3a.PE_times_LR")
# 
# 
# 
# # Print the loo
# kable(as.data.frame(loo)[,-(3:6)])

```


### Bayesian R squared 


```{r, warning=FALSE, message=FALSE}
# R2 = rbind(bR2.1,bR2.2,bR2.3)
# row.names(R2) =  c("Unsigned PE model","Unsigned PE + LR model","Unsigned PE * LR model")
# kable(R2,digits = 4)
```


### Checking the model

Plotting the chains
```{r, warning=FALSE, message=FALSE}
# Plot chains
plot(model, pars = "^b_", ask = FALSE, N=4)
```

R hat
```{r, warning=FALSE, message=FALSE}
# R hat for all parameters
stanplot(model, type="rhat_hist")
```


Posterior predictive check
```{r, warning=FALSE, message=FALSE}
# Plot chains
pp_check(model)
```


### Plotting the model


```{r, warning=FALSE, message=FALSE}
# Set parameters for plots
set_theme(base =theme_bw(base_size = 15, base_family = "")) # font size and theme
myColors = brewer.pal(3,"Set2") #colors
myColors = brewer.pal(3,"Set2") #colors



p = conditional_effects(model, effects = "unsigned_PE_reward",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS3_C1.pdf")


p = plot(p,plot=FALSE)[[1]]+
        xlab("Prediction error")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p
# f.4.e =p

p = conditional_effects(model, effects = "mbased_efficacy_feedback_locked",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Efficacy estimate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p

p = conditional_effects(model, effects = "LR_reward_raw_zscored",plot=FALSE)
pdf(file="C:/Users/igrahek/Dropbox (Brown)/CLPS-ShenhavLab/EEG_Studies/Experiments/LFXC_EEG/Manuscript/plots/Figures/FigureS3_C2.pdf")


p = plot(p,plot=FALSE)[[1]]+
        xlab("Learning rate")+
        ylab(expression(paste("P3b [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5,family = ""),
              text=element_text(colour="black", size = 18,family = ""),
              axis.text.x=element_text(colour="black", size = 18,family = ""),
              axis.text.y=element_text(colour="black", size = 18, face = "plain",hjust=0,family = ""),
              axis.title=element_text(size=20,colour = "black",vjust = 1,family = ""))


p
dev.off()
p

p = conditional_effects(model, effects = "unsigned_PE_reward:LR_reward_raw_zscored",plot=FALSE)


p = plot(p,plot=FALSE)[[1]]+
        xlab("Prediction error")+
        ylab(expression(paste("P3a [", mu,"V]")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))

p


# extract the per-subject effects

per_subject_P3a  = data.frame(matrix(ncol = 2, nrow = 40))
colnames(per_subject_P3a) = c("Prediction error","Learning rate")

x=as.data.frame(coef(model, pars = "unsigned_PE_reward"))

per_subject_P3a$`Prediction error` = x$SubID.Estimate.unsigned_PE_reward

x=as.data.frame(coef(model, pars = "LR_reward_raw_zscored"))

per_subject_P3a$`Learning rate` = x$SubID.Estimate.LR_reward_raw_zscored

per_subject_P3a=gather(per_subject_P3a, estimate, value, `Prediction error`, `Learning rate`)


p = ggplot(data = per_subject_P3a)+

    geom_point(aes(x=estimate,y=value),shape = 21, position=position_dodge(.9),size=5, color = "black",fill = NA,stroke = 1) +
  geom_hline(yintercept=0, linetype="dashed", color = "black") +
  
  
        xlab("Coeficient")+
        ylab(expression(paste("Regression coefficient value")))+
        #   geom_errorbar(size=1) +
        # geom_point(size=2) +
        theme(axis.line = element_line(size=1, colour = "black"),
              panel.grid.major = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.grid.minor = element_line(colour = "grey",size = 0.1,linetype = "dashed"),
              panel.border = element_blank(),
              panel.background = element_blank(),
              plot.title = element_text(size = 18,  face = "bold",hjust = 0.5),
              text=element_text(colour="black", size = 14),
              axis.text.x=element_text(colour="black", size = 14),
              axis.text.y=element_text(colour="black", size = 14, face = "plain",hjust=0),
              axis.title=element_text(size=18,colour = "black",vjust = 1))
p

```



### Table for the results

```{r, warning=FALSE, message=FALSE}
# Summary of the model
x=summary(model)[["fixed"]]
x$`HDI(95%)` = paste(format(round(x$`l-95% CI`, 2), nsmall = 2), format(round(x$`u-95% CI`, 2), nsmall = 2), sep=", ")
x$`l-95% CI` = NULL
x$`u-95% CI` = NULL
x$Bulk_ESS = NULL
x$Rhat = NULL
x$Tail_ESS = NULL

# add a row name column
names = rownames(x)
x = cbind(names,x)
rownames(x) = NULL

# extract the stats

#initialize the vector
estimates = NA

# Intercept
t = hypothesis(model,"Intercept <0")
estimates[1] = t$hypothesis$Post.Prob

# unsigned_PE_reward
t = hypothesis(model,"unsigned_PE_reward<0")
estimates[2] = t$hypothesis$Post.Prob

# LR_reward_raw_zscored
t = hypothesis(model,"LR_reward_raw_zscored<0")
estimates[3] = t$hypothesis$Post.Prob

# mbased_efficacy_feedback_locked
t = hypothesis(model,"mbased_efficacy_feedback_locked<0")
estimates[4] = t$hypothesis$Post.Prob

# unsigned_PE_reward:LR_reward_raw_zscored
t = hypothesis(model,"unsigned_PE_reward:LR_reward_raw_zscored  < 0")
estimates[5] = t$hypothesis$Post.Prob


# add the probabilities to the table
x$Posterior = estimates


# add BFs

# Intercept
t = hypothesis(model,"Intercept =0")
estimates[1] = 1/(t$hypothesis$Evid.Ratio)

# unsigned_PE_reward
t = hypothesis(model,"unsigned_PE_reward=0")
estimates[2] = 1/(t$hypothesis$Evid.Ratio)

# LR_reward_raw_zscored
t = hypothesis(model,"LR_reward_raw_zscored=0")
estimates[3] = 1/(t$hypothesis$Evid.Ratio)

# mbased_efficacy_feedback_locked
t = hypothesis(model,"mbased_efficacy_feedback_locked=0")
estimates[4] = 1/(t$hypothesis$Evid.Ratio)

# unsigned_PE_reward:LR_reward_raw_zscored
t = hypothesis(model,"unsigned_PE_reward:LR_reward_raw_zscored  = 0")
estimates[5] = 1/(t$hypothesis$Evid.Ratio)

# add the BFs to the table
x$BF = estimates

# turn into numeric to round
x$Estimate = as.numeric(x$Estimate)
x$Est.Error = as.numeric(x$Est.Error)

# edit the column names
kable(x,digits = 2,col.names = c("Parameter", "Estimate", "SE", "CI (95%)", "Posterior probability","BF10"),align = "lrrrrr")

```






### Inference about the model


Check the Prediction error effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_unsigned_PE_reward"]]

plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

p=hypothesis(model,"unsigned_PE_reward>0")

# p=hypothesis(model,"unsigned_PE_efficacy=0")
p
# plot(p)

```

Check the learning rate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_LR_reward_raw_zscored"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"LR_reward_raw_zscored>0")
```

Check the efficacy estimate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_mbased_efficacy_feedback_locked"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"mbased_efficacy_feedback_locked>0")
```


Check the Prediction error X learning rate effect

```{r, warning=FALSE, message=FALSE}
post = posterior_samples(model, "^b")
reward = post[["b_unsigned_PE_reward:LR_reward_raw_zscored"]]
plotPost(reward, xlab = "", col = "#b3cde0", cex = 1, showCurve = FALSE, compVal = 0)

hypothesis(model,"unsigned_PE_reward:LR_reward_raw_zscored>0")


```



